import torch
import torch.nn as nn
import torch.nn.functional as F
from ..backbones.ResNet_blocks import ConvBlock, ResidualBlock


class UltraFixedSpatialAttention(nn.Module):
    """è¶…ä¿®å¤ç‰ˆç©ºé—´æ³¨æ„åŠ› - å®Œå…¨é¿å…å½’ä¸€åŒ–é—®é¢˜"""
    
    def __init__(self, channels, kernel_sizes=[3], reduction=16):
        super().__init__()
        
        self.kernel_sizes = kernel_sizes
        
        # å®Œå…¨é¿å…å½’ä¸€åŒ–ï¼Œåªä½¿ç”¨å·ç§¯
        self.spatial_branches = nn.ModuleList()
        for ks in kernel_sizes:
            branch = nn.Sequential(
                nn.Conv2d(2, 1, kernel_size=ks, stride=1, padding=ks//2, bias=True),
                nn.ReLU(inplace=True)
            )
            self.spatial_branches.append(branch)
        
        # ç‰¹å¾èåˆ
        if len(kernel_sizes) > 1:
            self.fusion = nn.Sequential(
                nn.Conv2d(len(kernel_sizes), 1, kernel_size=1, bias=True),
                nn.Sigmoid()
            )
        else:
            self.fusion = nn.Sigmoid()
    
    def forward(self, x):
        # è®¡ç®—ç©ºé—´ç»Ÿè®¡
        avg_out = torch.mean(x, dim=1, keepdim=True)
        max_out, _ = torch.max(x, dim=1, keepdim=True)
        spatial_input = torch.cat([avg_out, max_out], dim=1)
        
        # å¤šå°ºåº¦å¤„ç†
        branch_outputs = []
        for branch in self.spatial_branches:
            branch_out = branch(spatial_input)
            branch_outputs.append(branch_out)
        
        # èåˆå¤šå°ºåº¦ç‰¹å¾
        if len(branch_outputs) > 1:
            fused = torch.cat(branch_outputs, dim=1)
            attention = self.fusion(fused)
        else:
            attention = self.fusion(branch_outputs[0])
        
        return x * attention

class UltraFixedCSFGModule(nn.Module):
    """
    è¶…ä¿®å¤ç‰ˆCSFGæ¨¡å— - å®Œå…¨è§£å†³æ‰€æœ‰å½’ä¸€åŒ–é—®é¢˜
    
    ä¸»è¦ä¿®å¤ï¼š
    1. å®Œå…¨ç§»é™¤æ‰€æœ‰å¯èƒ½æœ‰é—®é¢˜çš„å½’ä¸€åŒ–å±‚
    2. ä½¿ç”¨æœ€å®‰å…¨çš„GroupNormé…ç½®
    3. æ·»åŠ æ•°å€¼ç¨³å®šæ€§ä¿è¯
    4. æç®€åŒ–è®¾è®¡
    """
    
    def __init__(
        self,
        enc_channels,
        dec_channels,
        reduction_ratio=8,
        use_residual=True
    ):
        super().__init__()
        
        self.enc_channels = enc_channels
        self.dec_channels = dec_channels
        self.use_residual = use_residual
        
        print(f"UltraFixedCSFGModule: enc_channels={enc_channels}, dec_channels={dec_channels}")
        
        # å®‰å…¨çš„GroupNormè®¡ç®—å‡½æ•°
        def safe_group_norm(channels, min_groups=1):
            # ç¡®ä¿ç»„æ•°åˆç†
            if channels <= 4:
                return nn.Identity()  # å¯¹äºå¾ˆå°çš„é€šé“æ•°ï¼Œä¸ä½¿ç”¨å½’ä¸€åŒ–
            elif channels <= 8:
                return nn.GroupNorm(1, channels)  # åªæœ‰1ç»„
            elif channels <= 16:
                return nn.GroupNorm(2, channels)  # 2ç»„
            elif channels <= 32:
                return nn.GroupNorm(4, channels)  # 4ç»„
            else:
                groups = min(32, channels // 4)  # æœ€å¤š32ç»„ï¼Œæ¯ç»„è‡³å°‘4ä¸ªé€šé“
                return nn.GroupNorm(groups, channels)
        
        # 1. æç®€ç‰¹å¾å¯¹é½
        self.enc_align = nn.Sequential(
            nn.Conv2d(enc_channels, enc_channels, kernel_size=1, bias=True),
            safe_group_norm(enc_channels),
            nn.ReLU(inplace=True)
        )
        
        self.dec_align = nn.Sequential(
            nn.Conv2d(dec_channels, enc_channels, kernel_size=1, bias=True),
            safe_group_norm(enc_channels),
            nn.ReLU(inplace=True)
        )
        
        # 2. è¶…ç®€åŒ–çš„ä¸‰åˆ†æ”¯è®¾è®¡
        # Detailåˆ†æ”¯ - åªç”¨å·ç§¯
        self.detail_branch = nn.Sequential(
            nn.Conv2d(enc_channels, enc_channels, kernel_size=3, padding=1, bias=True),
            nn.ReLU(inplace=True)
        )
        
        # Localåˆ†æ”¯ - æœ€ç®€è®¾è®¡
        local_mid = max(enc_channels // 2, 1)
        self.local_branch = nn.Sequential(
            nn.Conv2d(enc_channels, local_mid, kernel_size=1, bias=True),
            nn.ReLU(inplace=True),
            nn.Conv2d(local_mid, enc_channels, kernel_size=3, padding=1, bias=True),
            nn.ReLU(inplace=True)
        )
        
        # Contextåˆ†æ”¯ - ç®€åŒ–è†¨èƒ€å·ç§¯
        self.context_branch = nn.Sequential(
            nn.Conv2d(enc_channels, enc_channels, kernel_size=3, padding=2, dilation=2, bias=True),
            nn.ReLU(inplace=True)
        )
        
        # 3. å®Œå…¨é‡æ–°è®¾è®¡çš„å…¨å±€åˆ†æ”¯ - é¿å…æ‰€æœ‰1x1é—®é¢˜
        global_mid = max(enc_channels // 4, 1)
        self.global_branch = nn.Sequential(
            # å…ˆé™ç»´ï¼Œé¿å…å¤§ç‰¹å¾å›¾ä¸Šçš„å…¨å±€æ± åŒ–
            nn.Conv2d(enc_channels, global_mid, kernel_size=1, bias=True),
            nn.ReLU(inplace=True),
            # ä½¿ç”¨æ›´å¤§çš„æ± åŒ–ï¼Œé¿å…1x1
            nn.AdaptiveAvgPool2d(2),  # æ± åŒ–åˆ°2x2
            # 2x2å·ç§¯å¤„ç†
            nn.Conv2d(global_mid, enc_channels, kernel_size=2, bias=True),
            # æœ€åæ± åŒ–åˆ°1x1
            nn.AdaptiveAvgPool2d(1),
            nn.Flatten(2, 3),  # å±•å¹³ä¸º(B, C, 1)
        )
        
        # ä½¿ç”¨ç®€å•çš„çº¿æ€§å±‚ç”Ÿæˆæƒé‡
        self.global_weight_gen = nn.Sequential(
            nn.Linear(enc_channels, enc_channels, bias=True),
            nn.Sigmoid()
        )
        
        # 4. è¶…ç®€åŒ–çš„è¯­ä¹‰å¼•å¯¼ç½‘ç»œ
        guidance_mid = max(dec_channels // 4, 4)  # è‡³å°‘4ä¸ªé€šé“
        self.semantic_guidance = nn.Sequential(
            # å…ˆé™ç»´
            nn.Conv2d(dec_channels, guidance_mid, kernel_size=1, bias=True),
            nn.ReLU(inplace=True),
            # æ± åŒ–åˆ°2x2
            nn.AdaptiveAvgPool2d(2),
            # 2x2å·ç§¯
            nn.Conv2d(guidance_mid, 4, kernel_size=2, bias=True),  # ç›´æ¥è¾“å‡º4ä¸ªæƒé‡é€šé“
            # æœ€åæ± åŒ–åˆ°1x1
            nn.AdaptiveAvgPool2d(1),
            nn.Flatten(),  # å±•å¹³ä¸º(B, 4)
            nn.Softmax(dim=1)
        )
        
        # 5. æœ€ç®€èåˆ
        self.adaptive_fusion = nn.Sequential(
            nn.Conv2d(enc_channels, enc_channels, kernel_size=1, bias=True),
            nn.ReLU(inplace=True)
        )
        
        # 6. ç®€åŒ–ç©ºé—´æ³¨æ„åŠ›
        self.spatial_attention = UltraFixedSpatialAttention(enc_channels, kernel_sizes=[3])
        
        # 7. æ®‹å·®è¿æ¥
        if use_residual:
            self.residual_projection = nn.Conv2d(enc_channels, enc_channels, kernel_size=1, bias=True)
            self.residual_weight = nn.Parameter(torch.tensor(0.1))  # æ›´å°çš„æ®‹å·®æƒé‡
        else:
            self.residual_projection = None
        
        # 8. æœ€ç»ˆå¤„ç† - æ— å½’ä¸€åŒ–
        self.final_activation = nn.ReLU(inplace=True)
        
        # 9. Dropout
        self.dropout = nn.Dropout2d(p=0.05)
        
        self._initialize_weights()
    
    def _initialize_weights(self):
        """è¶…ä¿å®ˆçš„æƒé‡åˆå§‹åŒ–"""
        for m in self.modules():
            if isinstance(m, nn.Conv2d):
                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')
                m.weight.data *= 0.05  # ææä¿å®ˆçš„åˆå§‹åŒ–
                if m.bias is not None:
                    nn.init.constant_(m.bias, 0.01)
                    
            elif isinstance(m, nn.Linear):
                nn.init.normal_(m.weight, 0, 0.0001)  # æå°çš„åˆå§‹åŒ–
                if m.bias is not None:
                    nn.init.constant_(m.bias, 0.01)
                    
            elif isinstance(m, nn.GroupNorm):
                if hasattr(m, 'weight') and m.weight is not None:
                    nn.init.constant_(m.weight, 1)
                if hasattr(m, 'bias') and m.bias is not None:
                    nn.init.constant_(m.bias, 0)
    
    def forward(self, x_enc, g_up):
        """è¶…ä¿®å¤ç‰ˆå‰å‘ä¼ æ’­"""
        # æå¼ºçš„è¾“å…¥é™åˆ¶
        x_enc = torch.clamp(x_enc, -0.1, 0.1)
        g_up = torch.clamp(g_up, -0.1, 0.1)
        
        # 1. å®‰å…¨çš„ç‰¹å¾å¯¹é½
        try:
            x_enc_aligned = self.enc_align(x_enc)
            g_up_aligned = self.dec_align(g_up)
            # ç®€å•ç›¸åŠ äº¤äº’
            cross_scale = x_enc_aligned + g_up_aligned
        except Exception as e:
            print(f"âš ï¸ ç‰¹å¾å¯¹é½å¤±è´¥: {e}")
            # æœ€ç®€å•çš„å¤‡é€‰æ–¹æ¡ˆ
            if g_up.shape[1] != x_enc.shape[1]:
                g_up = F.adaptive_avg_pool2d(g_up, 1)
                g_up = F.interpolate(g_up, size=x_enc.shape[2:], mode='nearest')
                g_up = F.pad(g_up, (0, 0, 0, 0, 0, x_enc.shape[1] - g_up.shape[1]))[:, :x_enc.shape[1]]
            cross_scale = (x_enc + g_up) * 0.5
        
        # 2. ä¸‰åˆ†æ”¯ç‰¹å¾æå–
        try:
            f_detail = self.detail_branch(cross_scale)
            f_local = self.local_branch(cross_scale)
            f_context = self.context_branch(cross_scale)
        except Exception as e:
            print(f"âš ï¸ åˆ†æ”¯ç‰¹å¾æå–å¤±è´¥: {e}")
            f_detail = f_local = f_context = cross_scale
        
        # 3. å…¨å±€åˆ†æ”¯
        try:
            global_features = self.global_branch(cross_scale)  # (B, C, 1)
            global_weights = self.global_weight_gen(global_features.squeeze(-1))  # (B, C)
            global_weights = global_weights.view(-1, self.enc_channels, 1, 1)
            f_global = cross_scale * global_weights
        except Exception as e:
            print(f"âš ï¸ å…¨å±€åˆ†æ”¯å¤±è´¥: {e}")
            f_global = cross_scale * 0.25
        
        # 4. è¯­ä¹‰å¼•å¯¼æƒé‡
        try:
            semantic_weights = self.semantic_guidance(g_up)  # (B, 4)
            # ç¡®ä¿æ˜¯4ç»´
            if semantic_weights.shape[1] != 4:
                semantic_weights = torch.ones(semantic_weights.shape[0], 4, device=semantic_weights.device) * 0.25
            
            alpha_detail = semantic_weights[:, 0:1].view(-1, 1, 1, 1)
            alpha_local = semantic_weights[:, 1:2].view(-1, 1, 1, 1)
            alpha_context = semantic_weights[:, 2:3].view(-1, 1, 1, 1)
            alpha_global = semantic_weights[:, 3:4].view(-1, 1, 1, 1)
        except Exception as e:
            print(f"âš ï¸ è¯­ä¹‰å¼•å¯¼å¤±è´¥: {e}")
            alpha_detail = alpha_local = alpha_context = alpha_global = 0.25
        
        # 5. ç‰¹å¾èåˆ
        try:
            x_fused = (alpha_detail * f_detail + 
                       alpha_local * f_local + 
                       alpha_context * f_context + 
                       alpha_global * f_global)
        except Exception as e:
            print(f"âš ï¸ ç‰¹å¾èåˆå¤±è´¥: {e}")
            x_fused = (f_detail + f_local + f_context + f_global) * 0.25
        
        # 6. åå¤„ç†
        try:
            x_fused = self.adaptive_fusion(x_fused)
            x_fused = self.spatial_attention(x_fused)
        except Exception as e:
            print(f"âš ï¸ åå¤„ç†å¤±è´¥: {e}")
        
        # 7. æ®‹å·®è¿æ¥
        if self.use_residual and self.residual_projection is not None:
            try:
                residual = self.residual_projection(x_enc)
                x_fused = x_fused + self.residual_weight * residual
            except Exception as e:
                print(f"âš ï¸ æ®‹å·®è¿æ¥å¤±è´¥: {e}")
        
        # 8. æœ€ç»ˆå¤„ç†
        x_fused = self.final_activation(x_fused)
        
        # 9. Dropoutå’Œè¾“å‡ºé™åˆ¶
        if self.training:
            x_fused = self.dropout(x_fused)
        
        x_fused = torch.clamp(x_fused, -0.1, 0.1)
        
        return x_fused
    
    def get_attention_weights(self, x_enc, g_up):
        """è·å–æ³¨æ„åŠ›æƒé‡"""
        with torch.no_grad():
            try:
                semantic_weights = self.semantic_guidance(g_up)
                return {
                    'weights_tensor': semantic_weights,
                    'device': semantic_weights.device,
                    'requires_sync': True
                }
            except Exception as e:
                print(f"âš ï¸ è·å–æ³¨æ„åŠ›æƒé‡å¤±è´¥: {e}")
                B = g_up.shape[0]
                default_weights = torch.ones(B, 4, device=g_up.device) * 0.25
                return {
                    'weights_tensor': default_weights,
                    'device': g_up.device,
                    'requires_sync': False
                }
    
    def get_attention_weights_legacy(self, x_enc, g_up):
        """å…¼å®¹æ¥å£"""
        weights_info = self.get_attention_weights(x_enc, g_up)
        weights = weights_info['weights_tensor']
        
        try:
            if weights.dim() == 2 and weights.shape[1] == 4:  # (B, 4)
                weights_cpu = weights.cpu().numpy()
                return {
                    'detail_weight': weights_cpu[:, 0],
                    'local_weight': weights_cpu[:, 1],
                    'context_weight': weights_cpu[:, 2],
                    'global_weight': weights_cpu[:, 3],
                    'weights_tensor': weights,
                    'device': weights.device
                }
        except Exception as e:
            print(f"âš ï¸ Legacyæƒé‡è½¬æ¢å¤±è´¥: {e}")
        
        # å¤‡ç”¨æ–¹æ¡ˆ
        B = g_up.shape[0]
        return {
            'detail_weight': [0.25] * B,
            'local_weight': [0.25] * B,
            'context_weight': [0.25] * B,
            'global_weight': [0.25] * B,
            'weights_tensor': torch.ones(B, 4, device=g_up.device) * 0.25,
            'device': g_up.device
        }


class UltraFixedCSFGSkipConnection(nn.Module):
    """è¶…ä¿®å¤ç‰ˆCSFGè·³è·ƒè¿æ¥"""
    
    def __init__(
        self,
        enc_channels,
        dec_channels,
        out_channels=None,
        reduction_ratio=8,
        use_residual=True
    ):
        super().__init__()
        
        if out_channels is None:
            out_channels = enc_channels
        
        self.enc_channels = enc_channels
        self.dec_channels = dec_channels
        self.out_channels = out_channels
        
        print(f"UltraFixedCSFGSkipConnection: enc={enc_channels}, dec={dec_channels}, out={out_channels}")
        
        # ä½¿ç”¨è¶…ä¿®å¤ç‰ˆCSFGæ¨¡å—
        self.csfg = UltraFixedCSFGModule(
            enc_channels=enc_channels,
            dec_channels=dec_channels,
            reduction_ratio=reduction_ratio,
            use_residual=use_residual
        )
        
        # å®‰å…¨çš„GroupNormå‡½æ•°
        def safe_group_norm(channels):
            if channels <= 4:
                return nn.Identity()
            elif channels <= 8:
                return nn.GroupNorm(1, channels)
            elif channels <= 16:
                return nn.GroupNorm(2, channels)
            else:
                groups = min(32, channels // 4)
                return nn.GroupNorm(groups, channels)
        
        # æç®€çš„åå¤„ç†ç½‘ç»œ
        concat_channels = enc_channels + dec_channels
        self.post_fusion = nn.Sequential(
            nn.Conv2d(concat_channels, out_channels, kernel_size=1, bias=True),
            safe_group_norm(out_channels),
            nn.ReLU(inplace=True),
            
            # ç²¾ç‚¼å±‚
            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1, bias=True),
            nn.ReLU(inplace=True)
        )
        
        # æç®€çš„å…¨å±€ä¸Šä¸‹æ–‡ - å®Œå…¨é¿å…1x1å½’ä¸€åŒ–
        context_mid = max(out_channels // 4, 1)
        self.global_context = nn.Sequential(
            nn.Conv2d(out_channels, context_mid, kernel_size=1, bias=True),
            nn.ReLU(inplace=True),
            nn.AdaptiveAvgPool2d(2),  # æ± åŒ–åˆ°2x2
            nn.Conv2d(context_mid, out_channels, kernel_size=2, bias=True),
            nn.AdaptiveAvgPool2d(1),  # æœ€åæ± åŒ–åˆ°1x1
            nn.Sigmoid()
        )
        
        # Dropout
        self.dropout = nn.Dropout2d(p=0.05)
        
        self._initialize_weights()
    
    def _initialize_weights(self):
        """è¶…ä¿å®ˆåˆå§‹åŒ–"""
        for m in self.modules():
            if isinstance(m, nn.Conv2d):
                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')
                m.weight.data *= 0.05  # æä¿å®ˆ
                if m.bias is not None:
                    nn.init.constant_(m.bias, 0.01)
            elif isinstance(m, nn.GroupNorm):
                if hasattr(m, 'weight') and m.weight is not None:
                    nn.init.constant_(m.weight, 1)
                if hasattr(m, 'bias') and m.bias is not None:
                    nn.init.constant_(m.bias, 0)
    
    def forward(self, x_enc, g_up):
        """è¶…ä¿®å¤ç‰ˆå‰å‘ä¼ æ’­"""
        # æå¼ºè¾“å…¥é™åˆ¶
        x_enc = torch.clamp(x_enc, -0.1, 0.1)
        g_up = torch.clamp(g_up, -0.1, 0.1)
        
        # 1. CSFGæ™ºèƒ½èåˆ
        try:
            x_fused = self.csfg(x_enc, g_up)
        except Exception as e:
            print(f"âš ï¸ CSFGèåˆå¤±è´¥ï¼Œä½¿ç”¨ç®€å•èåˆ: {e}")
            # æœ€å®‰å…¨çš„å¤‡é€‰æ–¹æ¡ˆ
            if x_enc.shape[2:] != g_up.shape[2:]:
                g_up = F.interpolate(g_up, size=x_enc.shape[2:], mode='nearest')
            if x_enc.shape[1] != g_up.shape[1]:
                if g_up.shape[1] < x_enc.shape[1]:
                    g_up = F.pad(g_up, (0, 0, 0, 0, 0, x_enc.shape[1] - g_up.shape[1]))
                else:
                    g_up = g_up[:, :x_enc.shape[1]]
            x_fused = (x_enc + g_up) * 0.5
        
        # 2. ç‰¹å¾æ‹¼æ¥
        try:
            if x_fused.shape[2:] != g_up.shape[2:]:
                g_up = F.interpolate(g_up, size=x_fused.shape[2:], mode='nearest')
            
            concat_features = torch.cat([x_fused, g_up], dim=1)
        except Exception as e:
            print(f"âš ï¸ ç‰¹å¾æ‹¼æ¥å¤±è´¥: {e}")
            concat_features = x_fused
        
        # 3. åå¤„ç†
        try:
            output = self.post_fusion(concat_features)
        except Exception as e:
            print(f"âš ï¸ åå¤„ç†å¤±è´¥: {e}")
            # æœ€ç®€å•çš„å¤‡é€‰
            if concat_features.shape[1] != self.out_channels:
                simple_conv = nn.Conv2d(concat_features.shape[1], self.out_channels, 1, bias=True).to(concat_features.device)
                nn.init.kaiming_normal_(simple_conv.weight)
                simple_conv.weight.data *= 0.05
                nn.init.constant_(simple_conv.bias, 0.01)
                output = simple_conv(concat_features)
            else:
                output = concat_features
        
        # 4. å…¨å±€ä¸Šä¸‹æ–‡å¢å¼º
        try:
            global_weight = self.global_context(output)
            output = output * global_weight
        except Exception as e:
            print(f"âš ï¸ å…¨å±€ä¸Šä¸‹æ–‡å¢å¼ºå¤±è´¥: {e}")
        
        # 5. Dropout
        if self.training:
            output = self.dropout(output)
        
        # è¾“å‡ºé™åˆ¶
        output = torch.clamp(output, -0.1, 0.1)
        
        return output


# =============================================================================
# æ›´æ–°æ‰€æœ‰åˆ«ååˆ°è¶…ä¿®å¤ç‰ˆ
# =============================================================================

# å‘åå…¼å®¹åˆ«å - ä½¿ç”¨è¶…ä¿®å¤ç‰ˆ
CSFGModule = UltraFixedCSFGModule
CSFGSkipConnection = UltraFixedCSFGSkipConnection
FixedCSFGModule = UltraFixedCSFGModule  # æ›¿æ¢ä¹‹å‰çš„ä¿®å¤ç‰ˆ
FixedCSFGSkipConnection = UltraFixedCSFGSkipConnection  # æ›¿æ¢ä¹‹å‰çš„ä¿®å¤ç‰ˆ
EnhancedCSFGModule = UltraFixedCSFGModule  # æ›¿æ¢åŸæ¥çš„å¢å¼ºç‰ˆ
EnhancedCSFGSkipConnection = UltraFixedCSFGSkipConnection  # æ›¿æ¢åŸæ¥çš„å¢å¼ºç‰ˆ


def create_csfg_module(
    enc_channels,
    dec_channels,
    reduction_ratio=8,
    use_residual=True
):
    """åˆ›å»ºè¶…ä¿®å¤ç‰ˆCSFGæ¨¡å—"""
    return UltraFixedCSFGModule(
        enc_channels=enc_channels,
        dec_channels=dec_channels,
        reduction_ratio=reduction_ratio,
        use_residual=use_residual
    )


def create_csfg_skip_connection(
    enc_channels,
    dec_channels,
    out_channels=None,
    reduction_ratio=8,
    use_residual=True
):
    """åˆ›å»ºè¶…ä¿®å¤ç‰ˆCSFGè·³è·ƒè¿æ¥"""
    return UltraFixedCSFGSkipConnection(
        enc_channels=enc_channels,
        dec_channels=dec_channels,
        out_channels=out_channels,
        reduction_ratio=reduction_ratio,
        use_residual=use_residual
    )

create_csfg = create_csfg_module


def csfg_base(enc_channels, dec_channels, **kwargs):
    """åŸºç¡€é…ç½®"""
    filtered_kwargs = {k: v for k, v in kwargs.items() 
                      if k not in ['enc_channels', 'dec_channels', 'reduction_ratio', 'use_residual']}
    
    return create_csfg_skip_connection(
        enc_channels=enc_channels,
        dec_channels=dec_channels,
        reduction_ratio=4,
        use_residual=True,
        **filtered_kwargs
    )


def csfg_skip_base(enc_channels, dec_channels, out_channels=None, **kwargs):
    """åŸºç¡€è·³è·ƒè¿æ¥é…ç½®"""
    return csfg_base(enc_channels, dec_channels, out_channels=out_channels, **kwargs)


# =============================================================================
# æµ‹è¯•å‡½æ•°
# =============================================================================

def test_ultra_fixed_csfg():
    """æµ‹è¯•è¶…ä¿®å¤ç‰ˆCSFG"""
    print("ğŸ¯ æµ‹è¯•è¶…ä¿®å¤ç‰ˆCSFG...")
    
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    
    # åˆ›å»ºè¶…ä¿®å¤ç‰ˆCSFGæ¨¡å—
    csfg = UltraFixedCSFGModule(enc_channels=64, dec_channels=32).to(device)
    csfg.train()  # è®­ç»ƒæ¨¡å¼æµ‹è¯•
    
    # æµ‹è¯•ä¸åŒç±»å‹çš„è¾“å…¥
    test_cases = {
        'random': torch.randn(2, 64, 32, 32).to(device),
        'zeros': torch.zeros(2, 64, 32, 32).to(device),
        'ones': torch.ones(2, 64, 32, 32).to(device),
        'small_values': torch.randn(2, 64, 32, 32).to(device) * 0.01,
    }
    
    dec_input = torch.randn(2, 32, 32, 32).to(device)
    
    print("æµ‹è¯•è¶…ä¿®å¤ç‰ˆCSFGåœ¨è®­ç»ƒæ¨¡å¼ä¸‹:")
    
    success_count = 0
    for case_name, test_input in test_cases.items():
        try:
            # å‰å‘ä¼ æ’­
            output = csfg(test_input, dec_input)
            
            # æ£€æŸ¥è¾“å‡º
            output_np = output.detach().cpu().numpy()
            zero_ratio = np.sum(output_np == 0) / output_np.size
            mean_val = np.mean(np.abs(output_np))
            std_val = np.std(output_np)
            
            print(f"  {case_name:12s}: âœ… é›¶æ¿€æ´»={zero_ratio:.3f}, å‡å€¼={mean_val:.6f}, æ ‡å‡†å·®={std_val:.6f}")
            
            # æ¢¯åº¦æµ‹è¯•
            test_input.requires_grad_(True)
            dec_input.requires_grad_(True)
            output = csfg(test_input, dec_input)
            loss = torch.mean(output ** 2)
            loss.backward()
            
            if test_input.grad is not None:
                grad_norm = torch.norm(test_input.grad).item()
                print(f"  {case_name:12s}: âœ… æ¢¯åº¦èŒƒæ•°={grad_norm:.6f}")
                success_count += 1
            else:
                print(f"  {case_name:12s}: âŒ æ— æ¢¯åº¦")
                
        except Exception as e:
            print(f"  {case_name:12s}: âŒ å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
    
    print(f"\nè¶…ä¿®å¤ç‰ˆCSFGæµ‹è¯•: {success_count}/{len(test_cases)} æˆåŠŸ")
    return success_count == len(test_cases)


if __name__ == "__main__":
    import numpy as np
    test_ultra_fixed_csfg()