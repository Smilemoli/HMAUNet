import torch
import torch.nn as nn
import torch.nn.functional as F
from ..backbones.vss_blocks import VSSBlock
from ..backbones.ResNet_blocks import ResidualBlock
from functools import partial
import math


class HMABottleneck(nn.Module):
    """
    å¢å¼ºç‰ˆHMAç“¶é¢ˆå±‚ - æå‡åˆ†å‰²æ€§èƒ½
    
    æ–°å¢ç‰¹æ€§ï¼š
    1. å¤šå°ºåº¦æ³¨æ„åŠ›æœºåˆ¶
    2. è‡ªé€‚åº”ç‰¹å¾èåˆ
    3. è¾¹ç•Œå¢å¼ºæ¨¡å—
    4. æ·±åº¦ç›‘ç£æ”¯æŒ
    5. åŠ¨æ€æƒé‡è°ƒæ•´
    """
    
    def __init__(
        self,
        in_channels,
        out_channels=None,
        d_state=16,
        num_levels=3,  # å¢åŠ å±‚æ•°ä»¥æå‡æ€§èƒ½
        drop_path_rate=0.1,  # é€‚åº¦çš„drop_pathæœ‰åŠ©äºæ³›åŒ–
        use_checkpoint=False,
        enhanced_features=True  # æ–°å¢ï¼šæ˜¯å¦å¯ç”¨å¢å¼ºç‰¹æ€§
    ):
        super().__init__()
        
        if out_channels is None:
            out_channels = in_channels
            
        self.in_channels = in_channels
        self.out_channels = out_channels
        self.num_levels = num_levels
        self.use_checkpoint = use_checkpoint
        self.enhanced_features = enhanced_features
        
        # åŠ¨æ€è°ƒæ•´drop_path
        self.drop_path_rate = drop_path_rate
        
        # ä¼˜åŒ–d_stateè®¾ç½®
        self.d_state = min(d_state, max(out_channels // 8, 16))
        
        print(f"Enhanced HMABottleneck: in_channels={in_channels}, out_channels={out_channels}, "
              f"d_state={self.d_state}, enhanced_features={enhanced_features}")
        
        # æ”¹è¿›çš„GroupNormå‡½æ•°
        def adaptive_group_norm(channels):
            if channels <= 8:
                return nn.GroupNorm(1, channels)
            elif channels <= 32:
                return nn.GroupNorm(min(4, channels // 4), channels)
            else:
                groups = min(32, max(8, channels // 16))
                return nn.GroupNorm(groups, channels)
        
        # 1. å¢å¼ºçš„è¾“å…¥å¤„ç† - æ·»åŠ æ³¨æ„åŠ›æœºåˆ¶
        self.input_stabilizer = nn.Sequential(
            nn.Conv2d(in_channels, out_channels, kernel_size=1, bias=False),
            adaptive_group_norm(out_channels),
            nn.GELU(),  # ä½¿ç”¨GELUæ¿€æ´»
            nn.Dropout2d(p=0.05)
        )
        
        # 2. å¤šå°ºåº¦æ³¨æ„åŠ›æ¨¡å— - å®Œå…¨ä¿®å¤ç‰ˆæœ¬
        if self.enhanced_features:
            self.multi_scale_attention = MultiScaleAttention(out_channels)
        
        # 3. æ”¹è¿›çš„ç‰¹å¾æç‚¼
        self.feature_refinement = nn.Sequential(
            ResidualBlock(out_channels, out_channels),
            nn.Conv2d(out_channels, out_channels, kernel_size=1, bias=False),
            adaptive_group_norm(out_channels),
            nn.GELU()
        )
        
        # 4. å¢å¼ºçš„Mambaå—
        self.mamba_block = VSSBlock(
            hidden_dim=out_channels,
            drop_path=drop_path_rate,
            norm_layer=partial(nn.LayerNorm, eps=1e-6),
            d_state=self.d_state
        )
        
        # 5. è‡ªé€‚åº”å¤šå°ºåº¦ç‰¹å¾æå–
        self.multi_scale_layers = nn.ModuleList()
        for i in range(self.num_levels):
            dilation = 2 ** i
            layer = AdaptiveMultiScaleBlock(
                out_channels, 
                dilation=dilation,
                enhanced=self.enhanced_features
            )
            self.multi_scale_layers.append(layer)
        
        # 6. è¾¹ç•Œå¢å¼ºæ¨¡å—
        if self.enhanced_features:
            self.boundary_enhancement = BoundaryEnhancementModule(out_channels)
        
        # 7. è‡ªé€‚åº”ç‰¹å¾èåˆ
        total_channels = out_channels * (self.num_levels + 2)  # +2 for input and mamba
        if self.enhanced_features:
            total_channels += out_channels  # +1 for boundary features
            
        self.adaptive_fusion = AdaptiveFeatureFusion(
            total_channels, 
            out_channels,
            enhanced=self.enhanced_features
        )
        
        # 8. è¾“å‡ºç¨³å®šåŒ– - æ·»åŠ æ³¨æ„åŠ›
        self.output_stabilizer = nn.Sequential(
            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1, bias=False),
            adaptive_group_norm(out_channels),
            nn.GELU(),
            ChannelAttention(out_channels) if self.enhanced_features else nn.Identity()
        )
        
        # 9. æ™ºèƒ½æ®‹å·®è¿æ¥
        if in_channels != out_channels:
            self.residual_projection = nn.Sequential(
                nn.Conv2d(in_channels, out_channels, kernel_size=1, bias=False),
                adaptive_group_norm(out_channels)
            )
        else:
            self.residual_projection = None
        
        # 10. åŠ¨æ€æƒé‡å‚æ•°
        self.mamba_weight = nn.Parameter(torch.tensor(0.3))  # å¢åŠ Mambaæƒé‡
        self.residual_weight = nn.Parameter(torch.tensor(0.5))
        self.boundary_weight = nn.Parameter(torch.tensor(0.2)) if self.enhanced_features else None
        
        # 11. æ·±åº¦ç›‘ç£è¾“å‡ºå¤´ï¼ˆå¯é€‰ï¼‰
        if self.enhanced_features:
            self.deep_supervision_head = nn.Conv2d(out_channels, 1, kernel_size=1)
        
        self._initialize_weights()
    
    def _initialize_weights(self):
        """æ”¹è¿›çš„æƒé‡åˆå§‹åŒ–"""
        for name, m in self.named_modules():
            if isinstance(m, nn.Conv2d):
                # ä½¿ç”¨Heåˆå§‹åŒ–
                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')
                if m.bias is not None:
                    nn.init.constant_(m.bias, 0)
                    
            elif isinstance(m, nn.GroupNorm):
                if hasattr(m, 'weight') and m.weight is not None:
                    nn.init.constant_(m.weight, 1)
                if hasattr(m, 'bias') and m.bias is not None:
                    nn.init.constant_(m.bias, 0)
                    
            elif isinstance(m, nn.Linear):
                nn.init.trunc_normal_(m.weight, std=0.02)
                if m.bias is not None:
                    nn.init.constant_(m.bias, 0)
        
        # åˆå§‹åŒ–åŠ¨æ€æƒé‡
        if hasattr(self, 'mamba_weight'):
            nn.init.constant_(self.mamba_weight, 0.3)
        if hasattr(self, 'residual_weight'):
            nn.init.constant_(self.residual_weight, 0.5)
        if hasattr(self, 'boundary_weight') and self.boundary_weight is not None:
            nn.init.constant_(self.boundary_weight, 0.2)
    
    def _safe_mamba_forward(self, x):
        """å®‰å…¨çš„Mambaå‰å‘ä¼ æ’­"""
        try:
            B, C, H, W = x.shape
            
            # ç»´åº¦è½¬æ¢ï¼š(B, C, H, W) -> (B, H, W, C)
            x_hwc = x.permute(0, 2, 3, 1).contiguous()
            
            # Mambaå¤„ç†
            x_out = self.mamba_block(x_hwc)
            
            # ç»´åº¦è½¬æ¢å›ï¼š(B, H, W, C) -> (B, C, H, W)
            x_chw = x_out.permute(0, 3, 1, 2).contiguous()
            
            return x_chw
            
        except Exception as e:
            print(f"âš ï¸ Mambaå¤„ç†å¤±è´¥: {e}")
            return x
    
    def forward(self, x_enc4, return_deep_supervision=False):
        """
        å¢å¼ºç‰ˆå‰å‘ä¼ æ’­
        """
        # ä¿å­˜æ®‹å·®
        x_residual = x_enc4
        
        # 1. è¾“å…¥ç¨³å®šåŒ–
        x = self.input_stabilizer(x_enc4)
        
        # 2. å¤šå°ºåº¦æ³¨æ„åŠ›ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        if self.enhanced_features:
            x_attended = self.multi_scale_attention(x)
            x = x + 0.1 * x_attended  # è½»é‡çº§èåˆ
        
        # 3. ç‰¹å¾æç‚¼
        x_refined = self.feature_refinement(x)
        
        # 4. Mambaå¤„ç†
        x_mamba = self._safe_mamba_forward(x_refined)
        x_mamba = x_refined + self.mamba_weight * (x_mamba - x_refined)
        
        # 5. å¤šå°ºåº¦ç‰¹å¾æå–
        multi_scale_features = [x_refined, x_mamba]
        
        for scale_layer in self.multi_scale_layers:
            try:
                scale_feat = scale_layer(x_refined)
                multi_scale_features.append(scale_feat)
            except Exception as e:
                print(f"âš ï¸ å¤šå°ºåº¦å¤„ç†å¤±è´¥: {e}")
                multi_scale_features.append(x_refined)
        
        # 6. è¾¹ç•Œå¢å¼ºï¼ˆå¦‚æœå¯ç”¨ï¼‰
        if self.enhanced_features:
            try:
                boundary_feat = self.boundary_enhancement(x_refined)
                multi_scale_features.append(boundary_feat)
            except Exception as e:
                print(f"âš ï¸ è¾¹ç•Œå¢å¼ºå¤±è´¥: {e}")
        
        # 7. è‡ªé€‚åº”ç‰¹å¾èåˆ
        try:
            x = self.adaptive_fusion(multi_scale_features)
        except Exception as e:
            print(f"âš ï¸ ç‰¹å¾èåˆå¤±è´¥: {e}")
            x = x_refined
        
        # 8. è¾“å‡ºç¨³å®šåŒ–
        x = self.output_stabilizer(x)
        
        # 9. æ®‹å·®è¿æ¥
        if self.residual_projection is not None:
            x_residual = self.residual_projection(x_residual)
        
        # åº”ç”¨æ®‹å·®è¿æ¥
        output = x + self.residual_weight * x_residual
        
        # æ·±åº¦ç›‘ç£è¾“å‡º
        deep_output = None
        if self.enhanced_features and hasattr(self, 'deep_supervision_head') and return_deep_supervision:
            deep_output = self.deep_supervision_head(output)
        
        if return_deep_supervision:
            return output, deep_output
        return output
    
    def get_feature_info(self):
        """è·å–ç‰¹å¾ä¿¡æ¯"""
        return {
            'in_channels': self.in_channels,
            'out_channels': self.out_channels,
            'num_levels': self.num_levels,
            'd_state': self.d_state,
            'drop_path_rate': self.drop_path_rate,
            'enhanced_features': self.enhanced_features,
            'mamba_weight': float(self.mamba_weight.item()),
            'residual_weight': float(self.residual_weight.item()),
        }


class MultiScaleAttention(nn.Module):
    """å¤šå°ºåº¦æ³¨æ„åŠ›æ¨¡å— - å®Œå…¨ä¿®å¤ç‰ˆæœ¬"""
    def __init__(self, channels):
        super().__init__()
        self.channels = channels
        
        # ä¸åŒå°ºåº¦çš„å·ç§¯
        self.scales = [1, 3, 5]
        self.num_scales = len(self.scales)
        
        # ç¡®ä¿æ¯ä¸ªå°ºåº¦çš„è¾“å‡ºé€šé“æ•°æ˜¯åˆç†çš„
        channels_per_scale = max(1, channels // self.num_scales)
        
        # å¤šå°ºåº¦å·ç§¯ - ä½¿ç”¨æ ‡å‡†å·ç§¯
        self.scale_convs = nn.ModuleList([
            nn.Conv2d(
                channels, 
                channels_per_scale, 
                kernel_size=scale, 
                padding=scale//2,
                bias=False
            )
            for scale in self.scales
        ])
        
        # è®¡ç®—æ‹¼æ¥åçš„å®é™…é€šé“æ•°
        self.concat_channels = channels_per_scale * self.num_scales
        
        # é€šé“é€‚é…å±‚ï¼ˆå¦‚æœéœ€è¦ï¼‰
        if self.concat_channels != channels:
            self.channel_adapter = nn.Conv2d(self.concat_channels, channels, 1, bias=False)
        else:
            self.channel_adapter = None
        
        # æ³¨æ„åŠ›æƒé‡ç”Ÿæˆ - ä½¿ç”¨å®é™…çš„æ‹¼æ¥é€šé“æ•°
        attention_input_channels = channels  # ä½¿ç”¨é€‚é…åçš„é€šé“æ•°
        
        self.attention_conv = nn.Sequential(
            nn.Conv2d(attention_input_channels, max(8, attention_input_channels // 4), 1, bias=False),
            nn.GELU(),
            nn.Conv2d(max(8, attention_input_channels // 4), channels, 1, bias=False),
            nn.Sigmoid()
        )
        
        print(f"MultiScaleAttention: channels={channels}, "
              f"channels_per_scale={channels_per_scale}, "
              f"concat_channels={self.concat_channels}")
        
    def forward(self, x):
        # å¤šå°ºåº¦ç‰¹å¾æå–
        scale_features = []
        for conv in self.scale_convs:
            scale_features.append(conv(x))
        
        # æ‹¼æ¥å¤šå°ºåº¦ç‰¹å¾
        multi_scale = torch.cat(scale_features, dim=1)
        
        # é€šé“é€‚é…ï¼ˆå¦‚æœéœ€è¦ï¼‰
        if self.channel_adapter is not None:
            multi_scale = self.channel_adapter(multi_scale)
        
        # ç”Ÿæˆæ³¨æ„åŠ›æƒé‡
        attention = self.attention_conv(multi_scale)
        
        # åº”ç”¨æ³¨æ„åŠ›
        return x * attention


class AdaptiveMultiScaleBlock(nn.Module):
    """è‡ªé€‚åº”å¤šå°ºåº¦å— - ä¿®å¤ç‰ˆæœ¬"""
    def __init__(self, channels, dilation=1, enhanced=True):
        super().__init__()
        self.enhanced = enhanced
        
        # ç¡®ä¿groupså‚æ•°åˆç†
        groups = min(channels, max(1, channels // 8))
        
        if enhanced:
            # ä½¿ç”¨å¯åˆ†ç¦»å·ç§¯æå‡æ•ˆç‡
            self.conv = nn.Sequential(
                nn.Conv2d(channels, channels, kernel_size=3, padding=dilation, 
                         dilation=dilation, groups=groups, bias=False),  # æ·±åº¦å·ç§¯
                nn.Conv2d(channels, channels, kernel_size=1, bias=False),  # ç‚¹å·ç§¯
                nn.GroupNorm(min(32, max(1, channels // 8)), channels),
                nn.GELU()
            )
        else:
            self.conv = nn.Sequential(
                nn.Conv2d(channels, channels, kernel_size=3, padding=dilation, 
                         dilation=dilation, bias=False),
                nn.GroupNorm(min(32, max(1, channels // 8)), channels),
                nn.GELU()
            )
    
    def forward(self, x):
        return self.conv(x)


class BoundaryEnhancementModule(nn.Module):
    """è¾¹ç•Œå¢å¼ºæ¨¡å— - æå‡åˆ†å‰²è¾¹ç¼˜ç²¾åº¦"""
    def __init__(self, channels):
        super().__init__()
        
        # Sobelç®—å­ç”¨äºè¾¹ç¼˜æ£€æµ‹
        self.register_buffer('sobel_x', torch.tensor([
            [-1, 0, 1],
            [-2, 0, 2], 
            [-1, 0, 1]
        ]).float().unsqueeze(0).unsqueeze(0))
        
        self.register_buffer('sobel_y', torch.tensor([
            [-1, -2, -1],
            [0, 0, 0],
            [1, 2, 1]
        ]).float().unsqueeze(0).unsqueeze(0))
        
        # è¾¹ç•Œç‰¹å¾å¤„ç†
        self.boundary_conv = nn.Sequential(
            nn.Conv2d(channels + 2, channels, kernel_size=3, padding=1, bias=False),
            nn.GroupNorm(min(32, max(1, channels // 8)), channels),
            nn.GELU(),
            nn.Conv2d(channels, channels, kernel_size=1, bias=False)
        )
        
    def forward(self, x):
        B, C, H, W = x.shape
        
        # è®¡ç®—æ¢¯åº¦ï¼ˆè¾¹ç¼˜ä¿¡æ¯ï¼‰
        x_gray = torch.mean(x, dim=1, keepdim=True)  # è½¬ä¸ºç°åº¦
        
        # åº”ç”¨Sobelç®—å­
        grad_x = F.conv2d(x_gray, self.sobel_x.repeat(1, 1, 1, 1), padding=1)
        grad_y = F.conv2d(x_gray, self.sobel_y.repeat(1, 1, 1, 1), padding=1)
        
        # åˆå¹¶æ¢¯åº¦ä¿¡æ¯
        boundary_info = torch.cat([x, grad_x, grad_y], dim=1)
        
        # å¤„ç†è¾¹ç•Œç‰¹å¾
        boundary_enhanced = self.boundary_conv(boundary_info)
        
        return boundary_enhanced


class AdaptiveFeatureFusion(nn.Module):
    """è‡ªé€‚åº”ç‰¹å¾èåˆæ¨¡å— - ä¿®å¤ç‰ˆæœ¬"""
    def __init__(self, in_channels, out_channels, enhanced=True):
        super().__init__()
        self.enhanced = enhanced
        
        if enhanced:
            # ä½¿ç”¨æ³¨æ„åŠ›æœºåˆ¶çš„èåˆ
            mid_channels = max(32, out_channels * 2)  # ç¡®ä¿ä¸­é—´å±‚æœ‰è¶³å¤Ÿçš„é€šé“æ•°
            
            self.fusion = nn.Sequential(
                nn.Conv2d(in_channels, mid_channels, kernel_size=1, bias=False),
                nn.GroupNorm(min(32, max(1, mid_channels // 8)), mid_channels),
                nn.GELU(),
                nn.Conv2d(mid_channels, out_channels, kernel_size=3, padding=1, bias=False),
                nn.GroupNorm(min(32, max(1, out_channels // 8)), out_channels),
                nn.GELU()
            )
            
            # ç‰¹å¾æƒé‡ç”Ÿæˆ
            self.weight_gen = nn.Sequential(
                nn.AdaptiveAvgPool2d(1),
                nn.Conv2d(in_channels, max(8, in_channels // 4), 1, bias=False),
                nn.GELU(),
                nn.Conv2d(max(8, in_channels // 4), out_channels, 1, bias=False),
                nn.Sigmoid()
            )
        else:
            self.fusion = nn.Sequential(
                nn.Conv2d(in_channels, out_channels, kernel_size=1, bias=False),
                nn.GroupNorm(min(32, max(1, out_channels // 8)), out_channels),
                nn.GELU()
            )
    
    def forward(self, feature_list):
        # æ‹¼æ¥æ‰€æœ‰ç‰¹å¾
        fused_features = torch.cat(feature_list, dim=1)
        
        # åŸºç¡€èåˆ
        output = self.fusion(fused_features)
        
        # å¦‚æœå¯ç”¨å¢å¼ºæ¨¡å¼ï¼Œåº”ç”¨æ³¨æ„åŠ›æƒé‡
        if self.enhanced and hasattr(self, 'weight_gen'):
            weights = self.weight_gen(fused_features)
            output = output * weights
        
        return output


class ChannelAttention(nn.Module):
    """é€šé“æ³¨æ„åŠ›æ¨¡å— - ä¿®å¤ç‰ˆæœ¬"""
    def __init__(self, channels, reduction=16):
        super().__init__()
        self.avg_pool = nn.AdaptiveAvgPool2d(1)
        self.max_pool = nn.AdaptiveMaxPool2d(1)
        
        # ç¡®ä¿reduced_channelsè‡³å°‘ä¸º1
        reduced_channels = max(1, channels // reduction)
        
        self.fc = nn.Sequential(
            nn.Conv2d(channels, reduced_channels, 1, bias=False),
            nn.GELU(),
            nn.Conv2d(reduced_channels, channels, 1, bias=False)
        )
        
        self.sigmoid = nn.Sigmoid()
        
    def forward(self, x):
        avg_out = self.fc(self.avg_pool(x))
        max_out = self.fc(self.max_pool(x))
        attention = self.sigmoid(avg_out + max_out)
        return x * attention


# =============================================================================
# å·¥å‚å‡½æ•°å’Œé¢„å®šä¹‰é…ç½®
# =============================================================================

def create_hma_bottleneck(
    in_channels,
    out_channels=None,
    d_state=16,
    num_levels=3,
    drop_path_rate=0.1,
    use_checkpoint=False,
    enhanced_features=True
):
    """åˆ›å»ºHMAç“¶é¢ˆå±‚çš„å·¥å‚å‡½æ•°"""
    return HMABottleneck(
        in_channels=in_channels,
        out_channels=out_channels,
        d_state=d_state,
        num_levels=num_levels,
        drop_path_rate=drop_path_rate,
        use_checkpoint=use_checkpoint,
        enhanced_features=enhanced_features
    )


def hma_bottleneck_base(in_channels, out_channels=None, **kwargs):
    """åŸºç¡€HMAç“¶é¢ˆå±‚é…ç½® - å¢å¼ºç‰ˆ"""
    return create_hma_bottleneck(
        in_channels=in_channels,
        out_channels=out_channels,
        d_state=16,
        num_levels=3,
        drop_path_rate=0.1,
        use_checkpoint=False,
        enhanced_features=True,
        **kwargs
    )


# å‘åå…¼å®¹çš„åˆ«å
HMAModule = HMABottleneck
create_hma_module = create_hma_bottleneck
hma_base = hma_bottleneck_base


# =============================================================================
# æµ‹è¯•å‡½æ•°
# =============================================================================

def test_hma_bottleneck():
    """æµ‹è¯•å¢å¼ºç‰ˆHMAç“¶é¢ˆå±‚"""
    print("ğŸ¯ æµ‹è¯•å¢å¼ºç‰ˆHMAç“¶é¢ˆå±‚...")
    
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    
    # åˆ›å»ºå¢å¼ºç‰ˆHMAç“¶é¢ˆå±‚
    hma = HMABottleneck(
        in_channels=256, 
        out_channels=256,
        enhanced_features=True
    ).to(device)
    hma.eval()
    
    # æµ‹è¯•ä¸åŒè¾“å…¥
    test_cases = {
        'normal': torch.randn(2, 256, 16, 16).to(device),
        'small': torch.randn(2, 256, 8, 8).to(device),
        'large': torch.randn(2, 256, 32, 32).to(device),
    }
    
    print("æµ‹è¯•å¢å¼ºç‰ˆHMAç“¶é¢ˆå±‚:")
    
    success_count = 0
    total_tests = len(test_cases)
    
    for case_name, test_input in test_cases.items():
        try:
            # æµ‹è¯•æ­£å¸¸å‰å‘ä¼ æ’­
            with torch.no_grad():
                output = hma(test_input)
                
            # æµ‹è¯•æ·±åº¦ç›‘ç£
            with torch.no_grad():
                output, deep_out = hma(test_input, return_deep_supervision=True)
            
            # æ£€æŸ¥è¾“å‡º
            assert output.shape == test_input.shape, f"Shape mismatch: {output.shape} vs {test_input.shape}"
            
            if deep_out is not None:
                expected_deep_shape = (test_input.shape[0], 1, test_input.shape[2], test_input.shape[3])
                assert deep_out.shape == expected_deep_shape, f"Deep supervision shape mismatch"
            
            print(f"  {case_name:8s}: âœ… å½¢çŠ¶åŒ¹é…ï¼Œæ·±åº¦ç›‘ç£æ­£å¸¸")
            success_count += 1
                
        except Exception as e:
            print(f"  {case_name:8s}: âŒ å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
    
    print(f"\nå¢å¼ºç‰ˆHMAç“¶é¢ˆå±‚æµ‹è¯•: {success_count}/{total_tests} æˆåŠŸ")
    
    # æ‰“å°ç‰¹å¾ä¿¡æ¯
    try:
        feature_info = hma.get_feature_info()
        print("\nç‰¹å¾ä¿¡æ¯:")
        for key, value in feature_info.items():
            print(f"  {key}: {value}")
    except Exception as e:
        print(f"âš ï¸ æ— æ³•è·å–ç‰¹å¾ä¿¡æ¯: {e}")
    
    return success_count == total_tests


if __name__ == "__main__":
    import numpy as np
    test_hma_bottleneck()