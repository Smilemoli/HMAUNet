import os
import numpy as np
import torch
import cv2
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms
from PIL import Image
import albumentations as A
from albumentations.pytorch import ToTensorV2
import glob
from typing import Optional, Callable, Tuple, List
import hashlib


class IronSpectrumDataset(Dataset):
    """
    é“è°±å›¾åƒåˆ†å‰²æ•°æ®é›†
    
    æ”¯æŒçš„æ•°æ®æ ¼å¼ï¼š
    - å›¾åƒï¼šPNGæ ¼å¼ (.png)
    - æ ‡ç­¾ï¼šäºŒå€¼åŒ–æ©ç  (.png)
    """
    
    def __init__(
        self,
        img_dir: str,
        mask_dir: str,
        img_size: int = 512,
        is_train: bool = True,
        image_list: Optional[List[str]] = None,
        transform: Optional[Callable] = None,
        normalize: bool = True,
        augment: bool = True
    ):
        """
        Args:
            img_dir: å›¾åƒç›®å½•è·¯å¾„
            mask_dir: æ ‡ç­¾ç›®å½•è·¯å¾„
            img_size: å›¾åƒå°ºå¯¸
            is_train: æ˜¯å¦ä¸ºè®­ç»ƒæ¨¡å¼
            image_list: æŒ‡å®šçš„å›¾åƒæ–‡ä»¶åˆ—è¡¨ï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨ç›®å½•ä¸‹æ‰€æœ‰å›¾åƒ
            transform: è‡ªå®šä¹‰å˜æ¢
            normalize: æ˜¯å¦å½’ä¸€åŒ–å›¾åƒ
            augment: æ˜¯å¦è¿›è¡Œæ•°æ®å¢å¼º
        """
        self.img_dir = img_dir
        self.mask_dir = mask_dir
        self.img_size = img_size
        self.is_train = is_train
        self.normalize = normalize
        
        # è·å–å›¾åƒæ–‡ä»¶åˆ—è¡¨
        if image_list is not None:
            self.image_files = image_list
        else:
            self.image_files = self._get_image_files()
        
        # ç¡®ä¿å±æ€§åç§°ä¸€è‡´ - æ·»åŠ image_listå±æ€§ä»¥ä¿æŒå…¼å®¹æ€§
        self.image_list = self.image_files
        
        if len(self.image_files) == 0:
            raise ValueError(f"åœ¨ {self.img_dir} ä¸­æœªæ‰¾åˆ°PNGå›¾åƒæ–‡ä»¶")
        
        print(f"åœ¨ {'è®­ç»ƒ' if is_train else 'éªŒè¯/æµ‹è¯•'} é›†ä¸­æ‰¾åˆ° {len(self.image_files)} å¼ PNGå›¾åƒ")
        
        # è®¾ç½®å˜æ¢
        if transform is not None:
            self.transform = transform
        else:
            self.transform = self._get_default_transforms(augment and is_train)
    
    def _get_image_files(self):
        """è·å–æ‰€æœ‰PNGå›¾åƒæ–‡ä»¶"""
        print(f"ğŸ” æ­£åœ¨æ‰«æç›®å½•: {self.img_dir}")
        
        # åªæ‰«æPNGæ ¼å¼å›¾ç‰‡
        pattern = os.path.join(self.img_dir, '*.png')
        files = glob.glob(pattern)
        print(f"   æ‰«æ *.png: æ‰¾åˆ° {len(files)} ä¸ªæ–‡ä»¶")
        
        # åªä¿ç•™æ–‡ä»¶åï¼Œä¸åŒ…å«è·¯å¾„
        image_files = [os.path.basename(f) for f in files]
        
        # æ’åºç¡®ä¿ä¸€è‡´æ€§
        image_files.sort()
        print(f"æ€»å…±æ‰¾åˆ° {len(image_files)} ä¸ªPNGå›¾åƒæ–‡ä»¶")
        
        return image_files
    
    def _get_default_transforms(self, augment: bool = False):
        """è·å–é»˜è®¤çš„æ•°æ®å˜æ¢"""
        transforms_list = []
        
        # åŸºç¡€å˜æ¢
        transforms_list.extend([
            A.Resize(height=self.img_size, width=self.img_size),
        ])
        
        # æ•°æ®å¢å¼º (ä»…è®­ç»ƒæ—¶)
        if augment:
            transforms_list.extend([
                A.HorizontalFlip(p=0.5),
                A.VerticalFlip(p=0.3),
                A.RandomRotate90(p=0.5),
                A.ShiftScaleRotate(
                    shift_limit=0.1,
                    scale_limit=0.1,
                    rotate_limit=15,
                    p=0.5
                ),
                A.RandomBrightnessContrast(
                    brightness_limit=0.2,
                    contrast_limit=0.2,
                    p=0.5
                ),
                A.GaussNoise(var_limit=(10.0, 50.0), p=0.3),
                A.ElasticTransform(p=0.3),
            ])
        
        # å½’ä¸€åŒ–å’Œè½¬æ¢ä¸ºå¼ é‡
        if self.normalize:
            transforms_list.append(
                A.Normalize(
                    mean=[0.485, 0.456, 0.406],  # ImageNetæ ‡å‡†
                    std=[0.229, 0.224, 0.225],
                    max_pixel_value=255.0
                )
            )
        
        transforms_list.append(ToTensorV2())
        
        return A.Compose(transforms_list)
    
    def _get_mask_path(self, image_filename: str) -> str:
        """æ ¹æ®å›¾åƒæ–‡ä»¶åè·å–å¯¹åº”çš„æ ‡ç­¾è·¯å¾„"""
        # PNGå›¾åƒå¯¹åº”PNGæ ‡ç­¾
        mask_path = os.path.join(self.mask_dir, image_filename)
        return mask_path
    
    def __len__(self):
        return len(self.image_files)
    
    def __getitem__(self, idx):
        # è·å–å›¾åƒå’Œæ ‡ç­¾è·¯å¾„
        image_filename = self.image_files[idx]
        img_path = os.path.join(self.img_dir, image_filename)
        mask_path = self._get_mask_path(image_filename)
        
        # è¯»å–å›¾åƒ
        image = cv2.imread(img_path)
        if image is None:
            raise ValueError(f"æ— æ³•åŠ è½½å›¾åƒ: {img_path}")
        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        
        # è¯»å–æ ‡ç­¾
        if os.path.exists(mask_path):
            mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)
            if mask is None:
                raise ValueError(f"æ— æ³•åŠ è½½æ©ç : {mask_path}")
            
            # äºŒå€¼åŒ–æ ‡ç­¾ (0: èƒŒæ™¯, 1: å‰æ™¯)
            mask = (mask > 127).astype(np.uint8)
        else:
            # å¦‚æœæ²¡æœ‰æ ‡ç­¾æ–‡ä»¶ï¼Œåˆ›å»ºç©ºæ ‡ç­¾
            mask = np.zeros(
                (image.shape[0], image.shape[1]), 
                dtype=np.uint8
            )
            print(f"âš ï¸  æœªæ‰¾åˆ° {image_filename} çš„æ©ç æ–‡ä»¶ï¼Œä½¿ç”¨ç©ºæ©ç ")
        
        # åº”ç”¨å˜æ¢
        if self.transform:
            transformed = self.transform(image=image, mask=mask)
            image = transformed['image']
            mask = transformed['mask']
        
        # ç¡®ä¿maskæ˜¯floatç±»å‹å¹¶ä¸”å€¼åœ¨[0,1]èŒƒå›´å†…
        if mask.dtype == torch.uint8:
            mask = mask.float()
        
        # ä¸ºåˆ†å‰²ä»»åŠ¡æ·»åŠ é€šé“ç»´åº¦
        if len(mask.shape) == 2:
            mask = mask.unsqueeze(0)  # (H, W) -> (1, H, W)
        
        return {
            'image': image,
            'mask': mask,
            'filename': image_filename,
            'image_path': img_path,
            'mask_path': mask_path
        }
    
    def get_sample_names(self):
        """è·å–æ‰€æœ‰æ ·æœ¬åç§°"""
        return [os.path.splitext(f)[0] for f in self.image_files]


def get_fixed_split(all_images: List[str], split_ratio: float = 0.8) -> Tuple[List[str], List[str]]:
    """
    åŸºäºå“ˆå¸Œå€¼çš„å›ºå®šæ•°æ®é›†åˆ’åˆ†
    
    Args:
        all_images: æ‰€æœ‰å›¾åƒæ–‡ä»¶ååˆ—è¡¨
        split_ratio: è®­ç»ƒé›†æ¯”ä¾‹
        
    Returns:
        (train_images, val_images): è®­ç»ƒé›†å’ŒéªŒè¯é›†å›¾åƒåˆ—è¡¨
    """
    def get_hash_value(filename):
        """è·å–æ–‡ä»¶åçš„å“ˆå¸Œå€¼"""
        return int(hashlib.md5(filename.encode()).hexdigest(), 16)
    
    # æŒ‰æ–‡ä»¶åæ’åºç¡®ä¿ä¸€è‡´æ€§
    sorted_images = sorted(all_images)
    
    # è®¡ç®—æ¯ä¸ªæ–‡ä»¶çš„å“ˆå¸Œå€¼å¹¶æ’åº
    image_hash_pairs = [(img, get_hash_value(img)) for img in sorted_images]
    image_hash_pairs.sort(key=lambda x: x[1])  # æŒ‰å“ˆå¸Œå€¼æ’åº
    
    # è®¡ç®—è®­ç»ƒé›†å¤§å°
    train_size = int(len(sorted_images) * split_ratio)
    
    # åŸºäºå“ˆå¸Œå€¼æ’åºçš„ç»“æœè¿›è¡Œåˆ’åˆ†
    train_images = [pair[0] for pair in image_hash_pairs[:train_size]]
    val_images = [pair[0] for pair in image_hash_pairs[train_size:]]
    
    # ç¡®ä¿éªŒè¯é›†è‡³å°‘æœ‰ä¸€å®šæ•°é‡
    min_val_size = max(1, int(len(sorted_images) * 0.1))  # è‡³å°‘10%
    if len(val_images) < min_val_size:
        # é‡æ–°è°ƒæ•´
        train_size = len(sorted_images) - min_val_size
        train_images = [pair[0] for pair in image_hash_pairs[:train_size]]
        val_images = [pair[0] for pair in image_hash_pairs[train_size:]]
    
    return train_images, val_images


def create_train_val_dataloaders(
    train_img_dir: str,
    train_mask_dir: str,
    batch_size: int = 16,
    img_size: int = 512,
    num_workers: int = 4,
    split_ratio: float = 0.8,
    train_transform: Optional[Callable] = None,
    val_transform: Optional[Callable] = None,
    pin_memory: bool = True
) -> Tuple[DataLoader, DataLoader]:
    """
    ä»è®­ç»ƒæ•°æ®åˆ›å»ºè®­ç»ƒå’ŒéªŒè¯æ•°æ®åŠ è½½å™¨ï¼ˆå›ºå®šåˆ’åˆ†ï¼‰
    
    Args:
        train_img_dir: è®­ç»ƒå›¾åƒç›®å½•
        train_mask_dir: è®­ç»ƒæ©ç ç›®å½•
        batch_size: æ‰¹æ¬¡å¤§å°
        img_size: å›¾åƒå°ºå¯¸
        num_workers: æ•°æ®åŠ è½½å·¥ä½œè¿›ç¨‹æ•°
        split_ratio: è®­ç»ƒé›†æ¯”ä¾‹
        train_transform: è®­ç»ƒé›†è‡ªå®šä¹‰å˜æ¢
        val_transform: éªŒè¯é›†è‡ªå®šä¹‰å˜æ¢
        pin_memory: æ˜¯å¦ä½¿ç”¨å›ºå®šå†…å­˜
        
    Returns:
        (train_loader, val_loader): è®­ç»ƒå’ŒéªŒè¯æ•°æ®åŠ è½½å™¨
    """
    
    print("ğŸ”§ ä»è®­ç»ƒæ•°æ®ä¸­åˆ›å»ºå›ºå®šåˆ’åˆ†çš„è®­ç»ƒé›†å’ŒéªŒè¯é›†")
    
    # è·å–æ‰€æœ‰PNGå›¾åƒæ–‡ä»¶
    print(f"ğŸ” æ­£åœ¨æ‰«æè®­ç»ƒç›®å½•: {train_img_dir}")
    pattern = os.path.join(train_img_dir, '*.png')
    files = glob.glob(pattern)
    print(f"   æ‰«æ *.png: æ‰¾åˆ° {len(files)} ä¸ªæ–‡ä»¶")
    
    all_images = [os.path.basename(f) for f in files]
    all_images = sorted(list(set(all_images)))  # å»é‡å¹¶æ’åº
    print(f"æ€»å…±æ‰«æåˆ° {len(all_images)} ä¸ªPNGå›¾åƒæ–‡ä»¶")
    
    if len(all_images) == 0:
        raise ValueError(f"åœ¨ {train_img_dir} ä¸­æœªæ‰¾åˆ°PNGå›¾åƒæ–‡ä»¶")
    
    # ä½¿ç”¨å›ºå®šåˆ’åˆ†
    train_images, val_images = get_fixed_split(all_images, split_ratio)
    print(f"ğŸ“Š ä½¿ç”¨å›ºå®šåˆ’åˆ†ç­–ç•¥:")
    print(f"   è®­ç»ƒé›†: {len(train_images)} å¼ å›¾åƒ")
    print(f"   éªŒè¯é›†: {len(val_images)} å¼ å›¾åƒ")
    print(f"   éªŒè¯é›†æ¯”ä¾‹: {len(val_images)/len(all_images):.1%}")
    
    # åˆ›å»ºè®­ç»ƒå’ŒéªŒè¯æ•°æ®é›†
    train_dataset = IronSpectrumDataset(
        img_dir=train_img_dir,
        mask_dir=train_mask_dir,
        img_size=img_size,
        is_train=True,
        image_list=train_images,
        transform=train_transform,
        augment=True
    )
    val_dataset = IronSpectrumDataset(
        img_dir=train_img_dir,
        mask_dir=train_mask_dir,
        img_size=img_size,
        is_train=False,
        image_list=val_images,
        transform=val_transform,
        augment=False
    )
    
    # åˆ›å»ºæ•°æ®åŠ è½½å™¨
    train_loader = DataLoader(
        train_dataset,
        batch_size=batch_size,
        shuffle=True,
        num_workers=num_workers,
        pin_memory=pin_memory,
        drop_last=True
    )
    
    val_loader = DataLoader(
        val_dataset,
        batch_size=batch_size,
        shuffle=False,
        num_workers=num_workers,
        pin_memory=pin_memory
    )
    
    return train_loader, val_loader


def create_test_dataloader(
    test_img_dir: str,
    test_mask_dir: str,
    batch_size: int = 1,
    img_size: int = 512,
    num_workers: int = 4,
    transform: Optional[Callable] = None
) -> DataLoader:
    """
    åˆ›å»ºæµ‹è¯•æ•°æ®åŠ è½½å™¨ï¼ˆç‹¬ç«‹äºè®­ç»ƒæ•°æ®ï¼‰
    
    Args:
        test_img_dir: æµ‹è¯•å›¾åƒç›®å½•
        test_mask_dir: æµ‹è¯•æ©ç ç›®å½•
        batch_size: æ‰¹æ¬¡å¤§å°ï¼ˆæµ‹è¯•æ—¶é€šå¸¸ä¸º1ï¼‰
        img_size: å›¾åƒå°ºå¯¸
        num_workers: æ•°æ®åŠ è½½å·¥ä½œè¿›ç¨‹æ•°
        transform: è‡ªå®šä¹‰å˜æ¢
        
    Returns:
        test_loader: æµ‹è¯•æ•°æ®åŠ è½½å™¨
    """
    print("ğŸ”§ åˆ›å»ºæµ‹è¯•æ•°æ®åŠ è½½å™¨ï¼ˆç‹¬ç«‹æµ‹è¯•é›†ï¼‰")
    
    test_dataset = IronSpectrumDataset(
        img_dir=test_img_dir,
        mask_dir=test_mask_dir,
        img_size=img_size,
        is_train=False,
        transform=transform,
        augment=False
    )
    
    test_loader = DataLoader(
        test_dataset,
        batch_size=batch_size,
        shuffle=False,
        num_workers=num_workers,
        pin_memory=True
    )
    
    print(f"âœ… æµ‹è¯•æ•°æ®åŠ è½½å™¨åˆ›å»ºå®Œæˆ:")
    print(f"   æ‰¹æ¬¡æ•°é‡: {len(test_loader)}")
    print(f"   æ ·æœ¬æ€»æ•°: {len(test_dataset)}")
    print(f"   æ‰¹æ¬¡å¤§å°: {batch_size}")
    
    return test_loader


def save_split_info(train_images: List[str], val_images: List[str], save_path: str):
    """ä¿å­˜æ•°æ®é›†åˆ’åˆ†ä¿¡æ¯åˆ°æ–‡ä»¶"""
    os.makedirs(os.path.dirname(save_path), exist_ok=True)
    
    with open(save_path, 'w', encoding='utf-8') as f:
        f.write("=== æ•°æ®é›†åˆ’åˆ†ä¿¡æ¯ ===\n")
        f.write(f"è®­ç»ƒé›†æ•°é‡: {len(train_images)}\n")
        f.write(f"éªŒè¯é›†æ•°é‡: {len(val_images)}\n")
        f.write(f"æ€»æ•°é‡: {len(train_images) + len(val_images)}\n")
        f.write(f"éªŒè¯é›†æ¯”ä¾‹: {len(val_images)/(len(train_images) + len(val_images)):.1%}\n\n")
        
        f.write("è®­ç»ƒé›†å›¾åƒ:\n")
        for img in sorted(train_images):
            f.write(f"  {img}\n")
        
        f.write("\néªŒè¯é›†å›¾åƒ:\n")
        for img in sorted(val_images):
            f.write(f"  {img}\n")
    
    print(f"ğŸ“ æ•°æ®é›†åˆ’åˆ†ä¿¡æ¯å·²ä¿å­˜è‡³: {save_path}")


def verify_data_structure(train_img_dir: str, train_mask_dir: str, test_img_dir: str, test_mask_dir: str):
    """éªŒè¯æ•°æ®ç»“æ„æ˜¯å¦æ­£ç¡®"""
    print("ğŸ” éªŒè¯æ•°æ®ç»“æ„...")
    
    def check_directory(path, description):
        if os.path.exists(path):
            png_files = [f for f in os.listdir(path) if f.endswith('.png')]
            print(f"   {description}: {len(png_files)} ä¸ªPNGæ–‡ä»¶")
            return len(png_files)
        else:
            print(f"   {description}: ç›®å½•ä¸å­˜åœ¨")
            return 0
    
    print(f"ğŸ“ æ•°æ®ç»“æ„éªŒè¯:")
    train_img_count = check_directory(train_img_dir, "è®­ç»ƒå›¾åƒ")
    train_mask_count = check_directory(train_mask_dir, "è®­ç»ƒæ ‡ç­¾")
    test_img_count = check_directory(test_img_dir, "æµ‹è¯•å›¾åƒ")
    test_mask_count = check_directory(test_mask_dir, "æµ‹è¯•æ ‡ç­¾")
    
    if train_img_count > 0 and test_img_count > 0:
        print("âœ… æ•°æ®ç»“æ„éªŒè¯é€šè¿‡")
        return True
    else:
        print("âŒ æ•°æ®ç»“æ„éªŒè¯å¤±è´¥")
        return False


def test_dataset(train_img_dir: str = None, train_mask_dir: str = None, 
                test_img_dir: str = None, test_mask_dir: str = None):
    """
    æµ‹è¯•æ•°æ®é›†åŠŸèƒ½
    
    Args:
        train_img_dir: è®­ç»ƒå›¾åƒç›®å½•ï¼ˆå¯é€‰ï¼Œå¦‚æœä¸æä¾›åˆ™ä½¿ç”¨é»˜è®¤è·¯å¾„ï¼‰
        train_mask_dir: è®­ç»ƒæ ‡ç­¾ç›®å½•ï¼ˆå¯é€‰ï¼‰
        test_img_dir: æµ‹è¯•å›¾åƒç›®å½•ï¼ˆå¯é€‰ï¼‰
        test_mask_dir: æµ‹è¯•æ ‡ç­¾ç›®å½•ï¼ˆå¯é€‰ï¼‰
    """
    print("ğŸš€ é“è°±æ•°æ®é›†åŠŸèƒ½æµ‹è¯•")
    print("=" * 60)
    
    # å¦‚æœæ²¡æœ‰æä¾›è·¯å¾„ï¼Œä½¿ç”¨é»˜è®¤è·¯å¾„
    if train_img_dir is None:
        current_dir = os.getcwd()
        train_img_dir = os.path.join(current_dir, 'data', 'trainO', 'images')
        train_mask_dir = os.path.join(current_dir, 'data', 'trainO', 'labels')
        test_img_dir = os.path.join(current_dir, 'data', 'testO', 'images')
        test_mask_dir = os.path.join(current_dir, 'data', 'testO', 'labels')
    
    # éªŒè¯æ•°æ®ç»“æ„
    if not verify_data_structure(train_img_dir, train_mask_dir, test_img_dir, test_mask_dir):
        return
    
    try:
        # æµ‹è¯•è®­ç»ƒ/éªŒè¯æ•°æ®åŠ è½½å™¨
        print(f"\nğŸ”„ æµ‹è¯•è®­ç»ƒ/éªŒè¯æ•°æ®åŠ è½½å™¨...")
        train_loader, val_loader = create_train_val_dataloaders(
            train_img_dir=train_img_dir,
            train_mask_dir=train_mask_dir,
            batch_size=4,
            img_size=512,
            num_workers=0,
            split_ratio=0.8
        )
        
        print(f"\nğŸ“ˆ è®­ç»ƒ/éªŒè¯æ•°æ®åŠ è½½å™¨åˆ›å»ºæˆåŠŸ!")
        print(f"   è®­ç»ƒé›†æ‰¹æ¬¡æ•°é‡: {len(train_loader)}")
        print(f"   éªŒè¯é›†æ‰¹æ¬¡æ•°é‡: {len(val_loader)}")
        
        # æµ‹è¯•åŠ è½½ä¸€ä¸ªæ‰¹æ¬¡
        if len(train_loader) > 0:
            for batch in train_loader:
                print(f"\nğŸ” è®­ç»ƒæ‰¹æ¬¡æ•°æ®:")
                print(f"   å›¾åƒå¼ é‡å½¢çŠ¶: {batch['image'].shape}")
                print(f"   æ ‡ç­¾å¼ é‡å½¢çŠ¶: {batch['mask'].shape}")
                print(f"   å›¾åƒæ•°å€¼èŒƒå›´: [{batch['image'].min():.3f}, {batch['image'].max():.3f}]")
                print(f"   æ ‡ç­¾æ•°å€¼èŒƒå›´: [{batch['mask'].min():.3f}, {batch['mask'].max():.3f}]")
                break
        
        # æµ‹è¯•æµ‹è¯•æ•°æ®åŠ è½½å™¨
        print(f"\nğŸ”„ æµ‹è¯•æµ‹è¯•æ•°æ®åŠ è½½å™¨...")
        test_loader = create_test_dataloader(
            test_img_dir=test_img_dir,
            test_mask_dir=test_mask_dir,
            batch_size=1,
            img_size=512,
            num_workers=0
        )
        
        print(f"\nâœ… æ•°æ®é›†åŠŸèƒ½æµ‹è¯•å®Œæˆ!")
        
    except Exception as e:
        print(f"âŒ æ•°æ®é›†æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    # å¯ä»¥åœ¨è¿™é‡Œä¼ å…¥è‡ªå®šä¹‰è·¯å¾„è¿›è¡Œæµ‹è¯•
    test_dataset()
# import os
# import numpy as np
# import torch
# import cv2
# from torch.utils.data import Dataset, DataLoader
# from torchvision import transforms
# from PIL import Image
# import albumentations as A
# from albumentations.pytorch import ToTensorV2
# import glob
# from typing import Optional, Callable, Tuple, List
# import hashlib
# import random


# class MixupDataset(Dataset):
#     """
#     æ”¯æŒMixupçš„æ•°æ®é›†åŒ…è£…å™¨
    
#     åœ¨æ•°æ®é›†å±‚é¢å®ç°Mixupï¼Œè‡ªåŠ¨å¤„ç†æ ·æœ¬æ··åˆå’Œæ ‡ç­¾èåˆ
#     """
    
#     def __init__(
#         self,
#         base_dataset: Dataset,
#         mixup_alpha: float = 1.0,
#         mixup_prob: float = 0.5,
#         mixup_mode: str = 'mixup',
#         enable_mixup: bool = True
#     ):
#         """
#         Args:
#             base_dataset: åŸºç¡€æ•°æ®é›†
#             mixup_alpha: Betaåˆ†å¸ƒå‚æ•°ï¼Œæ§åˆ¶æ··åˆå¼ºåº¦
#             mixup_prob: åº”ç”¨Mixupçš„æ¦‚ç‡
#             mixup_mode: æ··åˆæ¨¡å¼ ['mixup', 'cutmix', 'segmix']
#             enable_mixup: æ˜¯å¦å¯ç”¨Mixup
#         """
#         self.base_dataset = base_dataset
#         self.mixup_alpha = mixup_alpha
#         self.mixup_prob = mixup_prob
#         self.mixup_mode = mixup_mode
#         self.enable_mixup = enable_mixup
        
#         # ç¼“å­˜æ•°æ®é›†é•¿åº¦
#         self._length = len(base_dataset)
        
#         # ä¸ºsegmixæ¨¡å¼é¢„è®¡ç®—å‰æ™¯æ¯”ä¾‹
#         if mixup_mode == 'segmix':
#             self._compute_foreground_ratios()
    
#     def _compute_foreground_ratios(self):
#         """é¢„è®¡ç®—æ‰€æœ‰æ ·æœ¬çš„å‰æ™¯æ¯”ä¾‹ï¼Œç”¨äºæ™ºèƒ½é…å¯¹"""
#         print("ğŸ” é¢„è®¡ç®—å‰æ™¯æ¯”ä¾‹ç”¨äºæ™ºèƒ½Mixup...")
#         self.fg_ratios = []
        
#         for i in range(min(100, len(self.base_dataset))):  # é‡‡æ ·éƒ¨åˆ†æ ·æœ¬
#             try:
#                 sample = self.base_dataset[i]
#                 mask = sample['mask']
#                 if isinstance(mask, torch.Tensor):
#                     fg_ratio = mask.mean().item()
#                 else:
#                     fg_ratio = np.mean(mask)
#                 self.fg_ratios.append(fg_ratio)
#             except:
#                 self.fg_ratios.append(0.1)  # é»˜è®¤å€¼
        
#         # æ‰©å±•åˆ°å…¨éƒ¨æ ·æœ¬
#         while len(self.fg_ratios) < len(self.base_dataset):
#             self.fg_ratios.extend(self.fg_ratios[:min(100, len(self.base_dataset))])
        
#         self.fg_ratios = self.fg_ratios[:len(self.base_dataset)]
#         print(f"âœ… å‰æ™¯æ¯”ä¾‹è®¡ç®—å®Œæˆï¼Œå¹³å‡å‰æ™¯æ¯”ä¾‹: {np.mean(self.fg_ratios):.3f}")
    
#     def __len__(self):
#         return self._length
    
#     def _get_lambda(self):
#         """é‡‡æ ·æ··åˆå‚æ•°Î»"""
#         if self.mixup_alpha > 0:
#             return np.random.beta(self.mixup_alpha, self.mixup_alpha)
#         else:
#             return 1.0
    
#     def _rand_bbox(self, size, lam):
#         """ä¸ºCutMixç”Ÿæˆéšæœºè¾¹ç•Œæ¡†"""
#         H, W = size[-2:]
#         cut_rat = np.sqrt(1. - lam)
#         cut_w = int(W * cut_rat)
#         cut_h = int(H * cut_rat)

#         # éšæœºä¸­å¿ƒç‚¹
#         cx = np.random.randint(W)
#         cy = np.random.randint(H)

#         bbx1 = np.clip(cx - cut_w // 2, 0, W)
#         bby1 = np.clip(cy - cut_h // 2, 0, H)
#         bbx2 = np.clip(cx + cut_w // 2, 0, W)
#         bby2 = np.clip(cy + cut_h // 2, 0, H)

#         return bbx1, bby1, bbx2, bby2
    
#     def _segmix_smart_pairing(self, idx):
#         """æ™ºèƒ½é…å¯¹ï¼šå‰æ™¯å°‘çš„å’Œå‰æ™¯å¤šçš„é…å¯¹"""
#         if not hasattr(self, 'fg_ratios'):
#             return np.random.randint(0, len(self.base_dataset))
        
#         current_fg = self.fg_ratios[idx]
        
#         # å¯»æ‰¾äº’è¡¥çš„æ ·æœ¬
#         if current_fg < 0.2:  # å½“å‰æ ·æœ¬å‰æ™¯å°‘ï¼Œæ‰¾å‰æ™¯å¤šçš„
#             candidates = [i for i, fg in enumerate(self.fg_ratios) if fg > 0.3 and i != idx]
#         elif current_fg > 0.4:  # å½“å‰æ ·æœ¬å‰æ™¯å¤šï¼Œæ‰¾å‰æ™¯å°‘çš„
#             candidates = [i for i, fg in enumerate(self.fg_ratios) if fg < 0.3 and i != idx]
#         else:  # ä¸­ç­‰å‰æ™¯ï¼Œéšæœºé…å¯¹
#             candidates = [i for i in range(len(self.base_dataset)) if i != idx]
        
#         if candidates:
#             return np.random.choice(candidates)
#         else:
#             return np.random.randint(0, len(self.base_dataset))
    
#     def _apply_mixup(self, sample_a, sample_b, lam):
#         """åº”ç”¨æ ‡å‡†Mixup"""
#         mixed_image = lam * sample_a['image'] + (1 - lam) * sample_b['image']
#         mixed_mask = lam * sample_a['mask'] + (1 - lam) * sample_b['mask']
        
#         return {
#             'image': mixed_image,
#             'mask': mixed_mask,
#             'filename': f"mixup_{sample_a['filename']}_{sample_b['filename']}",
#             'image_path': sample_a['image_path'],
#             'mask_path': sample_a['mask_path'],
#             'is_mixup': True,
#             'mixup_lam': lam,
#             'mixup_mode': 'mixup'
#         }
    
#     def _apply_cutmix(self, sample_a, sample_b, lam):
#         """åº”ç”¨CutMix"""
#         mixed_image = sample_a['image'].clone()
#         mixed_mask = sample_a['mask'].clone()
        
#         # ç”Ÿæˆéšæœºè¾¹ç•Œæ¡†
#         bbx1, bby1, bbx2, bby2 = self._rand_bbox(mixed_image.shape, lam)
        
#         # åº”ç”¨CutMix
#         mixed_image[:, bby1:bby2, bbx1:bbx2] = sample_b['image'][:, bby1:bby2, bbx1:bbx2]
#         mixed_mask[:, bby1:bby2, bbx1:bbx2] = sample_b['mask'][:, bby1:bby2, bbx1:bbx2]
        
#         # è°ƒæ•´Î»åŸºäºå®é™…æ··åˆåŒºåŸŸ
#         actual_lam = 1 - ((bbx2 - bbx1) * (bby2 - bby1) / (mixed_image.shape[-1] * mixed_image.shape[-2]))
        
#         return {
#             'image': mixed_image,
#             'mask': mixed_mask,
#             'filename': f"cutmix_{sample_a['filename']}_{sample_b['filename']}",
#             'image_path': sample_a['image_path'],
#             'mask_path': sample_a['mask_path'],
#             'is_mixup': True,
#             'mixup_lam': actual_lam,
#             'mixup_mode': 'cutmix'
#         }
    
#     def _apply_segmix(self, sample_a, sample_b, lam):
#         """åº”ç”¨SegMix - åŸºäºåˆ†å‰²æ©ç çš„æ™ºèƒ½æ··åˆ"""
#         mask_a = sample_a['mask']
#         mask_b = sample_b['mask']
        
#         # ç¡®ä¿æ©ç æ˜¯2Dçš„ (H, W)ï¼Œå¦‚æœæ˜¯3Dåˆ™å–ç¬¬ä¸€ä¸ªé€šé“
#         if isinstance(mask_a, torch.Tensor):
#             if len(mask_a.shape) == 3:
#                 mask_a_2d = mask_a[0]  # å–ç¬¬ä¸€ä¸ªé€šé“
#                 mask_b_2d = mask_b[0]
#             else:
#                 mask_a_2d = mask_a
#                 mask_b_2d = mask_b
            
#             fg_a = (mask_a_2d > 0.5).float()
#             fg_b = (mask_b_2d > 0.5).float()
            
#             # ç”Ÿæˆæ™ºèƒ½æ··åˆæ©ç  (H, W)
#             mix_mask = torch.rand_like(fg_a) < lam
            
#             # ä¿æŠ¤é‡è¦çš„å‰æ™¯åŒºåŸŸ
#             important_fg_a = fg_a * (torch.rand_like(fg_a) < 0.7)
#             important_fg_b = fg_b * (torch.rand_like(fg_b) < 0.7)
            
#             mix_mask = torch.where(important_fg_a > 0.5, torch.ones_like(mix_mask), mix_mask)
#             mix_mask = torch.where(important_fg_b > 0.5, torch.zeros_like(mix_mask), mix_mask)
            
#             mix_mask = mix_mask.float()  # (H, W)
            
#             # æ‰©å±•æ··åˆæ©ç åˆ°å›¾åƒé€šé“
#             # å›¾åƒ: (C, H, W), æ©ç mix_mask: (H, W)
#             C = sample_a['image'].shape[0]
#             img_mix_mask = mix_mask.unsqueeze(0).expand(C, -1, -1)  # (H, W) -> (1, H, W) -> (C, H, W)
            
#         else:
#             # NumPyå¤„ç†
#             if len(mask_a.shape) == 3:
#                 mask_a_2d = mask_a[0]
#                 mask_b_2d = mask_b[0]
#             else:
#                 mask_a_2d = mask_a
#                 mask_b_2d = mask_b
                
#             fg_a = (mask_a_2d > 0.5).astype(np.float32)
#             fg_b = (mask_b_2d > 0.5).astype(np.float32)
            
#             mix_mask = (np.random.rand(*fg_a.shape) < lam).astype(np.float32)
            
#             # ä¿æŠ¤é‡è¦çš„å‰æ™¯åŒºåŸŸ
#             important_fg_a = fg_a * (np.random.rand(*fg_a.shape) < 0.7)
#             important_fg_b = fg_b * (np.random.rand(*fg_b.shape) < 0.7)
            
#             mix_mask = np.where(important_fg_a > 0.5, 1.0, mix_mask)
#             mix_mask = np.where(important_fg_b > 0.5, 0.0, mix_mask)
            
#             # æ‰©å±•åˆ°å›¾åƒé€šé“
#             C = sample_a['image'].shape[0]
#             img_mix_mask = np.expand_dims(mix_mask, axis=0)
#             img_mix_mask = np.repeat(img_mix_mask, C, axis=0)
        
#         # åº”ç”¨æ··åˆ
#         mixed_image = img_mix_mask * sample_a['image'] + (1 - img_mix_mask) * sample_b['image']
        
#         # å¯¹äºæ©ç æ··åˆ
#         if isinstance(mask_a, torch.Tensor):
#             if len(mask_a.shape) == 3:
#                 # 3Dæ©ç  (1, H, W)
#                 mask_mix_mask = mix_mask.unsqueeze(0)  # (H, W) -> (1, H, W)
#                 mixed_mask = mask_mix_mask * sample_a['mask'] + (1 - mask_mix_mask) * sample_b['mask']
#             else:
#                 # 2Dæ©ç  (H, W)
#                 mixed_mask = mix_mask * sample_a['mask'] + (1 - mix_mask) * sample_b['mask']
#         else:
#             if len(mask_a.shape) == 3:
#                 mask_mix_mask = np.expand_dims(mix_mask, axis=0)
#                 mixed_mask = mask_mix_mask * sample_a['mask'] + (1 - mask_mix_mask) * sample_b['mask']
#             else:
#                 mixed_mask = mix_mask * sample_a['mask'] + (1 - mix_mask) * sample_b['mask']
        
#         # è®¡ç®—å®é™…çš„Î»
#         actual_lam = mix_mask.mean().item() if isinstance(mix_mask, torch.Tensor) else mix_mask.mean()
        
#         return {
#             'image': mixed_image,
#             'mask': mixed_mask,
#             'filename': f"segmix_{sample_a['filename']}_{sample_b['filename']}",
#             'image_path': sample_a['image_path'],
#             'mask_path': sample_a['mask_path'],
#             'is_mixup': True,
#             'mixup_lam': actual_lam,
#             'mixup_mode': 'segmix'
#         }
    
#     def __getitem__(self, idx):
#         # è·å–ä¸»æ ·æœ¬
#         sample_a = self.base_dataset[idx]
        
#         # ç¡®ä¿åŸºç¡€æ ·æœ¬æœ‰æ‰€æœ‰å¿…éœ€çš„é”®
#         if 'is_mixup' not in sample_a:
#             sample_a['is_mixup'] = False
#         if 'mixup_lam' not in sample_a:
#             sample_a['mixup_lam'] = 1.0
#         if 'mixup_mode' not in sample_a:
#             sample_a['mixup_mode'] = 'none'
        
#         # å†³å®šæ˜¯å¦åº”ç”¨Mixup
#         if not self.enable_mixup or np.random.random() > self.mixup_prob:
#             # ä¸åº”ç”¨Mixupï¼Œè¿”å›å¸¦æœ‰é»˜è®¤æ ‡è¯†çš„æ ·æœ¬
#             return sample_a
        
#         # é€‰æ‹©é…å¯¹æ ·æœ¬
#         if self.mixup_mode == 'segmix':
#             idx_b = self._segmix_smart_pairing(idx)
#         else:
#             idx_b = np.random.randint(0, len(self.base_dataset))
#             while idx_b == idx:  # ç¡®ä¿ä¸æ˜¯åŒä¸€ä¸ªæ ·æœ¬
#                 idx_b = np.random.randint(0, len(self.base_dataset))
        
#         sample_b = self.base_dataset[idx_b]
        
#         # ç¡®ä¿é…å¯¹æ ·æœ¬ä¹Ÿæœ‰æ‰€æœ‰å¿…éœ€çš„é”®
#         if 'is_mixup' not in sample_b:
#             sample_b['is_mixup'] = False
#         if 'mixup_lam' not in sample_b:
#             sample_b['mixup_lam'] = 1.0
#         if 'mixup_mode' not in sample_b:
#             sample_b['mixup_mode'] = 'none'
        
#         # è·å–æ··åˆå‚æ•°
#         lam = self._get_lambda()
        
#         # åº”ç”¨ç›¸åº”çš„æ··åˆç­–ç•¥
#         if self.mixup_mode == 'mixup':
#             mixed_sample = self._apply_mixup(sample_a, sample_b, lam)
#         elif self.mixup_mode == 'cutmix':
#             mixed_sample = self._apply_cutmix(sample_a, sample_b, lam)
#         elif self.mixup_mode == 'segmix':
#             mixed_sample = self._apply_segmix(sample_a, sample_b, lam)
#         else:
#             raise ValueError(f"ä¸æ”¯æŒçš„æ··åˆæ¨¡å¼: {self.mixup_mode}")
        
#         return mixed_sample


# class IronSpectrumDataset(Dataset):
#     """
#     é“è°±å›¾åƒåˆ†å‰²æ•°æ®é›†
    
#     æ”¯æŒçš„æ•°æ®æ ¼å¼ï¼š
#     - å›¾åƒï¼šPNGæ ¼å¼ (.png)
#     - æ ‡ç­¾ï¼šäºŒå€¼åŒ–æ©ç  (.png)
#     """
    
#     def __init__(
#         self,
#         img_dir: str,
#         mask_dir: str,
#         img_size: int = 512,
#         is_train: bool = True,
#         image_list: Optional[List[str]] = None,
#         transform: Optional[Callable] = None,
#         normalize: bool = True,
#         augment: bool = True,
#         # Mixupå‚æ•°
#         enable_mixup: bool = False,
#         mixup_alpha: float = 1.0,
#         mixup_prob: float = 0.5,
#         mixup_mode: str = 'mixup'
#     ):
#         """
#         Args:
#             img_dir: å›¾åƒç›®å½•è·¯å¾„
#             mask_dir: æ ‡ç­¾ç›®å½•è·¯å¾„
#             img_size: å›¾åƒå°ºå¯¸
#             is_train: æ˜¯å¦ä¸ºè®­ç»ƒæ¨¡å¼
#             image_list: æŒ‡å®šçš„å›¾åƒæ–‡ä»¶åˆ—è¡¨ï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨ç›®å½•ä¸‹æ‰€æœ‰å›¾åƒ
#             transform: è‡ªå®šä¹‰å˜æ¢
#             normalize: æ˜¯å¦å½’ä¸€åŒ–å›¾åƒ
#             augment: æ˜¯å¦è¿›è¡Œæ•°æ®å¢å¼º
#             enable_mixup: æ˜¯å¦å¯ç”¨Mixup (ä»…è®­ç»ƒæ—¶æœ‰æ•ˆ)
#             mixup_alpha: Mixupçš„alphaå‚æ•°
#             mixup_prob: åº”ç”¨Mixupçš„æ¦‚ç‡
#             mixup_mode: Mixupæ¨¡å¼ ['mixup', 'cutmix', 'segmix']
#         """
#         self.img_dir = img_dir
#         self.mask_dir = mask_dir
#         self.img_size = img_size
#         self.is_train = is_train
#         self.normalize = normalize
        
#         # Mixupå‚æ•°
#         self.enable_mixup = enable_mixup and is_train  # åªåœ¨è®­ç»ƒæ—¶å¯ç”¨
#         self.mixup_alpha = mixup_alpha
#         self.mixup_prob = mixup_prob
#         self.mixup_mode = mixup_mode
        
#         # è·å–å›¾åƒæ–‡ä»¶åˆ—è¡¨
#         if image_list is not None:
#             self.image_files = image_list
#         else:
#             self.image_files = self._get_image_files()
        
#         # ç¡®ä¿å±æ€§åç§°ä¸€è‡´ - æ·»åŠ image_listå±æ€§ä»¥ä¿æŒå…¼å®¹æ€§
#         self.image_list = self.image_files
        
#         if len(self.image_files) == 0:
#             raise ValueError(f"åœ¨ {self.img_dir} ä¸­æœªæ‰¾åˆ°PNGå›¾åƒæ–‡ä»¶")
        
#         mixup_info = f" (Mixup: {mixup_mode})" if self.enable_mixup else ""
#         print(f"åœ¨ {'è®­ç»ƒ' if is_train else 'éªŒè¯/æµ‹è¯•'} é›†ä¸­æ‰¾åˆ° {len(self.image_files)} å¼ PNGå›¾åƒ{mixup_info}")
        
#         # è®¾ç½®å˜æ¢
#         if transform is not None:
#             self.transform = transform
#         else:
#             self.transform = self._get_default_transforms(augment and is_train)
        
#         # å¦‚æœå¯ç”¨Mixupï¼Œé¢„è®¡ç®—å‰æ™¯æ¯”ä¾‹
#         if self.enable_mixup and self.mixup_mode == 'segmix':
#             self._compute_foreground_ratios()
    
#     def _compute_foreground_ratios(self):
#         """é¢„è®¡ç®—æ‰€æœ‰æ ·æœ¬çš„å‰æ™¯æ¯”ä¾‹ï¼Œç”¨äºæ™ºèƒ½é…å¯¹"""
#         print("ğŸ” é¢„è®¡ç®—å‰æ™¯æ¯”ä¾‹ç”¨äºæ™ºèƒ½Mixup...")
#         self.fg_ratios = []
        
#         # é‡‡æ ·éƒ¨åˆ†æ ·æœ¬è®¡ç®—å‰æ™¯æ¯”ä¾‹
#         sample_indices = list(range(0, len(self.image_files), max(1, len(self.image_files) // 50)))
        
#         for idx in sample_indices:
#             try:
#                 # ç®€å•åŠ è½½æ©ç 
#                 image_filename = self.image_files[idx]
#                 mask_path = self._get_mask_path(image_filename)
                
#                 if os.path.exists(mask_path):
#                     mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)
#                     if mask is not None:
#                         mask = (mask > 127).astype(np.float32)
#                         fg_ratio = mask.mean()
#                     else:
#                         fg_ratio = 0.1
#                 else:
#                     fg_ratio = 0.1
                
#                 self.fg_ratios.append(fg_ratio)
#             except:
#                 self.fg_ratios.append(0.1)
        
#         # æ‰©å±•åˆ°å…¨éƒ¨æ ·æœ¬
#         avg_fg_ratio = np.mean(self.fg_ratios)
#         self.fg_ratios = [avg_fg_ratio] * len(self.image_files)
        
#         # ä¸ºé‡‡æ ·çš„æ ·æœ¬è®¾ç½®å®é™…å€¼
#         for i, idx in enumerate(sample_indices):
#             if i < len(self.fg_ratios) and idx < len(self.fg_ratios):
#                 # å¹³æ»‘å¤„ç†
#                 pass
        
#         print(f"âœ… å‰æ™¯æ¯”ä¾‹ä¼°ç®—å®Œæˆï¼Œå¹³å‡å‰æ™¯æ¯”ä¾‹: {avg_fg_ratio:.3f}")
    
#     def _get_image_files(self):
#         """è·å–æ‰€æœ‰PNGå›¾åƒæ–‡ä»¶"""
#         print(f"ğŸ” æ­£åœ¨æ‰«æç›®å½•: {self.img_dir}")
        
#         # åªæ‰«æPNGæ ¼å¼å›¾ç‰‡
#         pattern = os.path.join(self.img_dir, '*.png')
#         files = glob.glob(pattern)
#         print(f"   æ‰«æ *.png: æ‰¾åˆ° {len(files)} ä¸ªæ–‡ä»¶")
        
#         # åªä¿ç•™æ–‡ä»¶åï¼Œä¸åŒ…å«è·¯å¾„
#         image_files = [os.path.basename(f) for f in files]
        
#         # æ’åºç¡®ä¿ä¸€è‡´æ€§
#         image_files.sort()
#         print(f"æ€»å…±æ‰¾åˆ° {len(image_files)} ä¸ªPNGå›¾åƒæ–‡ä»¶")
        
#         return image_files
    
#     def _get_default_transforms(self, augment: bool = False):
#         """è·å–é»˜è®¤çš„æ•°æ®å˜æ¢"""
#         transforms_list = []
        
#         # åŸºç¡€å˜æ¢
#         transforms_list.extend([
#             A.Resize(height=self.img_size, width=self.img_size),
#         ])
        
#         # æ•°æ®å¢å¼º (ä»…è®­ç»ƒæ—¶)
#         if augment:
#             transforms_list.extend([
#                 A.HorizontalFlip(p=0.5),
#                 A.VerticalFlip(p=0.3),
#                 A.RandomRotate90(p=0.5),
#                 A.ShiftScaleRotate(
#                     shift_limit=0.1,
#                     scale_limit=0.1,
#                     rotate_limit=15,
#                     p=0.5
#                 ),
#                 A.RandomBrightnessContrast(
#                     brightness_limit=0.2,
#                     contrast_limit=0.2,
#                     p=0.5
#                 ),
#                 A.GaussNoise(var_limit=(10.0, 50.0), p=0.3),
#                 A.ElasticTransform(p=0.3),
#             ])
        
#         # å½’ä¸€åŒ–å’Œè½¬æ¢ä¸ºå¼ é‡
#         if self.normalize:
#             transforms_list.append(
#                 A.Normalize(
#                     mean=[0.485, 0.456, 0.406],  # ImageNetæ ‡å‡†
#                     std=[0.229, 0.224, 0.225],
#                     max_pixel_value=255.0
#                 )
#             )
        
#         transforms_list.append(ToTensorV2())
        
#         return A.Compose(transforms_list)
    
#     def _get_mask_path(self, image_filename: str) -> str:
#         """æ ¹æ®å›¾åƒæ–‡ä»¶åè·å–å¯¹åº”çš„æ ‡ç­¾è·¯å¾„"""
#         # PNGå›¾åƒå¯¹åº”PNGæ ‡ç­¾
#         mask_path = os.path.join(self.mask_dir, image_filename)
#         return mask_path
    
#     def _get_lambda(self):
#         """é‡‡æ ·æ··åˆå‚æ•°Î»"""
#         if self.mixup_alpha > 0:
#             return np.random.beta(self.mixup_alpha, self.mixup_alpha)
#         else:
#             return 1.0
    
#     def _smart_pairing(self, idx):
#         """æ™ºèƒ½é…å¯¹ï¼šå‰æ™¯å°‘çš„å’Œå‰æ™¯å¤šçš„é…å¯¹"""
#         if not hasattr(self, 'fg_ratios'):
#             return np.random.randint(0, len(self.image_files))
        
#         current_fg = self.fg_ratios[idx]
        
#         # å¯»æ‰¾äº’è¡¥çš„æ ·æœ¬
#         if current_fg < 0.2:  # å½“å‰æ ·æœ¬å‰æ™¯å°‘ï¼Œæ‰¾å‰æ™¯å¤šçš„
#             candidates = [i for i, fg in enumerate(self.fg_ratios) if fg > 0.3 and i != idx]
#         elif current_fg > 0.4:  # å½“å‰æ ·æœ¬å‰æ™¯å¤šï¼Œæ‰¾å‰æ™¯å°‘çš„
#             candidates = [i for i, fg in enumerate(self.fg_ratios) if fg < 0.3 and i != idx]
#         else:  # ä¸­ç­‰å‰æ™¯ï¼Œéšæœºé…å¯¹
#             candidates = [i for i in range(len(self.image_files)) if i != idx]
        
#         if candidates:
#             return np.random.choice(candidates)
#         else:
#             return np.random.randint(0, len(self.image_files))
    
#     def _apply_mixup_augmentation(self, sample_a, sample_b, lam):
#         """åº”ç”¨Mixupæ•°æ®å¢å¼º"""
#         if self.mixup_mode == 'mixup':
#             # æ ‡å‡†Mixup
#             mixed_image = lam * sample_a['image'] + (1 - lam) * sample_b['image']
#             mixed_mask = lam * sample_a['mask'] + (1 - lam) * sample_b['mask']
            
#         elif self.mixup_mode == 'cutmix':
#             # CutMix
#             mixed_image = sample_a['image'].clone()
#             mixed_mask = sample_a['mask'].clone()
            
#             H, W = mixed_image.shape[-2:]
#             cut_rat = np.sqrt(1. - lam)
#             cut_w = int(W * cut_rat)
#             cut_h = int(H * cut_rat)
            
#             cx = np.random.randint(W)
#             cy = np.random.randint(H)
            
#             bbx1 = np.clip(cx - cut_w // 2, 0, W)
#             bby1 = np.clip(cy - cut_h // 2, 0, H)
#             bbx2 = np.clip(cx + cut_w // 2, 0, W)
#             bby2 = np.clip(cy + cut_h // 2, 0, H)
            
#             mixed_image[:, bby1:bby2, bbx1:bbx2] = sample_b['image'][:, bby1:bby2, bbx1:bbx2]
#             mixed_mask[:, bby1:bby2, bbx1:bbx2] = sample_b['mask'][:, bby1:bby2, bbx1:bbx2]
            
#             # è°ƒæ•´Î»
#             lam = 1 - ((bbx2 - bbx1) * (bby2 - bby1) / (W * H))
            
#         elif self.mixup_mode == 'segmix':
#             # SegMix - åŸºäºåˆ†å‰²æ©ç çš„æ™ºèƒ½æ··åˆ
#             mask_a = sample_a['mask']
#             mask_b = sample_b['mask']
            
#             # ç¡®ä¿æ©ç æ˜¯2Dçš„ (H, W)ï¼Œå¦‚æœæ˜¯3Dåˆ™å–ç¬¬ä¸€ä¸ªé€šé“
#             if len(mask_a.shape) == 3:
#                 mask_a_2d = mask_a[0]  # å–ç¬¬ä¸€ä¸ªé€šé“
#                 mask_b_2d = mask_b[0]
#             else:
#                 mask_a_2d = mask_a
#                 mask_b_2d = mask_b
            
#             fg_a = (mask_a_2d > 0.5).float()
#             fg_b = (mask_b_2d > 0.5).float()
            
#             # ç”Ÿæˆæ™ºèƒ½æ··åˆæ©ç  (H, W)
#             mix_mask = torch.rand_like(fg_a) < lam
            
#             # ä¿æŠ¤é‡è¦çš„å‰æ™¯åŒºåŸŸ
#             important_fg_a = fg_a * (torch.rand_like(fg_a) < 0.7)
#             important_fg_b = fg_b * (torch.rand_like(fg_b) < 0.7)
            
#             mix_mask = torch.where(important_fg_a > 0.5, torch.ones_like(mix_mask), mix_mask)
#             mix_mask = torch.where(important_fg_b > 0.5, torch.zeros_like(mix_mask), mix_mask)
            
#             mix_mask = mix_mask.float()  # (H, W)
            
#             # æ‰©å±•æ··åˆæ©ç åˆ°å›¾åƒé€šé“
#             # å›¾åƒé€šé“: (C, H, W), æˆ‘ä»¬éœ€è¦å°†mix_maskä»(H, W)æ‰©å±•åˆ°(C, H, W)
#             C, H, W = sample_a['image'].shape
#             img_mix_mask = mix_mask.unsqueeze(0).expand(C, H, W)  # (H, W) -> (1, H, W) -> (C, H, W)
            
#             # åº”ç”¨æ··åˆ
#             mixed_image = img_mix_mask * sample_a['image'] + (1 - img_mix_mask) * sample_b['image']
            
#             # å¯¹äºæ©ç ï¼Œå¦‚æœåŸæ¥æ˜¯3Dï¼Œä¿æŒ3Dï¼›å¦‚æœæ˜¯2Dï¼Œä¿æŒ2D
#             if len(mask_a.shape) == 3:
#                 # æ©ç æ˜¯3D (1, H, W)ï¼Œéœ€è¦å°†mix_maskæ‰©å±•ä¸ºç›¸åŒå½¢çŠ¶
#                 mask_mix_mask = mix_mask.unsqueeze(0)  # (H, W) -> (1, H, W)
#                 mixed_mask = mask_mix_mask * sample_a['mask'] + (1 - mask_mix_mask) * sample_b['mask']
#             else:
#                 # æ©ç æ˜¯2D (H, W)
#                 mixed_mask = mix_mask * sample_a['mask'] + (1 - mix_mask) * sample_b['mask']
            
#             lam = mix_mask.mean().item()
#         else:
#             raise ValueError(f"ä¸æ”¯æŒçš„æ··åˆæ¨¡å¼: {self.mixup_mode}")
        
#         # è¿”å›ç»Ÿä¸€æ ¼å¼çš„å­—å…¸ï¼Œç¡®ä¿æ‰€æœ‰é”®éƒ½å­˜åœ¨
#         return {
#             'image': mixed_image,
#             'mask': mixed_mask,
#             'filename': f"{self.mixup_mode}_{sample_a['filename']}_{sample_b['filename']}",
#             'image_path': sample_a['image_path'],
#             'mask_path': sample_a['mask_path'],
#             'is_mixup': True,
#             'mixup_lam': lam,
#             'mixup_mode': self.mixup_mode
#         }
#     def __len__(self):
#         return len(self.image_files)
    
#     def __getitem__(self, idx):
#         # è·å–ä¸»æ ·æœ¬
#         image_filename = self.image_files[idx]
#         img_path = os.path.join(self.img_dir, image_filename)
#         mask_path = self._get_mask_path(image_filename)
        
#         # è¯»å–å›¾åƒ
#         image = cv2.imread(img_path)
#         if image is None:
#             raise ValueError(f"æ— æ³•åŠ è½½å›¾åƒ: {img_path}")
#         image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        
#         # è¯»å–æ ‡ç­¾
#         if os.path.exists(mask_path):
#             mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)
#             if mask is None:
#                 raise ValueError(f"æ— æ³•åŠ è½½æ©ç : {mask_path}")
            
#             # äºŒå€¼åŒ–æ ‡ç­¾ (0: èƒŒæ™¯, 1: å‰æ™¯)
#             mask = (mask > 127).astype(np.uint8)
#         else:
#             # å¦‚æœæ²¡æœ‰æ ‡ç­¾æ–‡ä»¶ï¼Œåˆ›å»ºç©ºæ ‡ç­¾
#             mask = np.zeros(
#                 (image.shape[0], image.shape[1]), 
#                 dtype=np.uint8
#             )
#             print(f"âš ï¸  æœªæ‰¾åˆ° {image_filename} çš„æ©ç æ–‡ä»¶ï¼Œä½¿ç”¨ç©ºæ©ç ")
        
#         # åº”ç”¨å˜æ¢
#         if self.transform:
#             transformed = self.transform(image=image, mask=mask)
#             image = transformed['image']
#             mask = transformed['mask']
        
#         # ç¡®ä¿maskæ˜¯floatç±»å‹å¹¶ä¸”å€¼åœ¨[0,1]èŒƒå›´å†…
#         if mask.dtype == torch.uint8:
#             mask = mask.float()
        
#         # ä¸ºåˆ†å‰²ä»»åŠ¡æ·»åŠ é€šé“ç»´åº¦
#         if len(mask.shape) == 2:
#             mask = mask.unsqueeze(0)  # (H, W) -> (1, H, W)
        
#         # åˆ›å»ºåŸºç¡€æ ·æœ¬å­—å…¸ - ç¡®ä¿æ‰€æœ‰å¿…éœ€é”®éƒ½å­˜åœ¨
#         sample_a = {
#             'image': image,
#             'mask': mask,
#             'filename': image_filename,
#             'image_path': img_path,
#             'mask_path': mask_path,
#             'is_mixup': False,  # é»˜è®¤å€¼
#             'mixup_lam': 1.0,   # é»˜è®¤å€¼
#             'mixup_mode': 'none'  # é»˜è®¤å€¼
#         }
        
#         # å†³å®šæ˜¯å¦åº”ç”¨Mixup
#         if not self.enable_mixup or np.random.random() > self.mixup_prob:
#             # ä¸åº”ç”¨Mixupï¼Œè¿”å›å¸¦æœ‰é»˜è®¤å€¼çš„æ ·æœ¬
#             return sample_a
        
#         # é€‰æ‹©é…å¯¹æ ·æœ¬
#         if self.mixup_mode == 'segmix':
#             idx_b = self._smart_pairing(idx)
#         else:
#             idx_b = np.random.randint(0, len(self.image_files))
#             while idx_b == idx:
#                 idx_b = np.random.randint(0, len(self.image_files))
        
#         # é€’å½’è·å–é…å¯¹æ ·æœ¬ï¼ˆç¦ç”¨å…¶Mixupä»¥é¿å…åµŒå¥—ï¼‰
#         original_enable_mixup = self.enable_mixup
#         self.enable_mixup = False
#         sample_b = self.__getitem__(idx_b)
#         self.enable_mixup = original_enable_mixup
        
#         # åº”ç”¨Mixup
#         lam = self._get_lambda()
#         mixed_sample = self._apply_mixup_augmentation(sample_a, sample_b, lam)
        
#         return mixed_sample
    
#     def get_sample_names(self):
#         """è·å–æ‰€æœ‰æ ·æœ¬åç§°"""
#         return [os.path.splitext(f)[0] for f in self.image_files]


# # æ›´æ–°å·¥å‚å‡½æ•°ä»¥æ”¯æŒMixup
# def create_train_val_dataloaders(
#     train_img_dir: str,
#     train_mask_dir: str,
#     batch_size: int = 16,
#     img_size: int = 512,
#     num_workers: int = 4,
#     split_ratio: float = 0.8,
#     train_transform: Optional[Callable] = None,
#     val_transform: Optional[Callable] = None,
#     pin_memory: bool = True,
#     # Mixupå‚æ•°
#     enable_mixup: bool = False,
#     mixup_alpha: float = 1.0,
#     mixup_prob: float = 0.5,
#     mixup_mode: str = 'mixup'
# ) -> Tuple[DataLoader, DataLoader]:
#     """
#     ä»è®­ç»ƒæ•°æ®åˆ›å»ºè®­ç»ƒå’ŒéªŒè¯æ•°æ®åŠ è½½å™¨ï¼ˆå›ºå®šåˆ’åˆ†ï¼Œæ”¯æŒMixupï¼‰
    
#     Args:
#         train_img_dir: è®­ç»ƒå›¾åƒç›®å½•
#         train_mask_dir: è®­ç»ƒæ©ç ç›®å½•
#         batch_size: æ‰¹æ¬¡å¤§å°
#         img_size: å›¾åƒå°ºå¯¸
#         num_workers: æ•°æ®åŠ è½½å·¥ä½œè¿›ç¨‹æ•°
#         split_ratio: è®­ç»ƒé›†æ¯”ä¾‹
#         train_transform: è®­ç»ƒé›†è‡ªå®šä¹‰å˜æ¢
#         val_transform: éªŒè¯é›†è‡ªå®šä¹‰å˜æ¢
#         pin_memory: æ˜¯å¦ä½¿ç”¨å›ºå®šå†…å­˜
#         enable_mixup: æ˜¯å¦å¯ç”¨Mixup (ä»…è®­ç»ƒé›†)
#         mixup_alpha: Mixupçš„alphaå‚æ•°
#         mixup_prob: åº”ç”¨Mixupçš„æ¦‚ç‡
#         mixup_mode: Mixupæ¨¡å¼ ['mixup', 'cutmix', 'segmix']
        
#     Returns:
#         (train_loader, val_loader): è®­ç»ƒå’ŒéªŒè¯æ•°æ®åŠ è½½å™¨
#     """
    
#     mixup_info = f" (Mixup: {mixup_mode})" if enable_mixup else ""
#     print(f"ğŸ”§ ä»è®­ç»ƒæ•°æ®ä¸­åˆ›å»ºå›ºå®šåˆ’åˆ†çš„è®­ç»ƒé›†å’ŒéªŒè¯é›†{mixup_info}")
    
#     # è·å–æ‰€æœ‰PNGå›¾åƒæ–‡ä»¶
#     print(f"ğŸ” æ­£åœ¨æ‰«æè®­ç»ƒç›®å½•: {train_img_dir}")
#     pattern = os.path.join(train_img_dir, '*.png')
#     files = glob.glob(pattern)
#     print(f"   æ‰«æ *.png: æ‰¾åˆ° {len(files)} ä¸ªæ–‡ä»¶")
    
#     all_images = [os.path.basename(f) for f in files]
#     all_images = sorted(list(set(all_images)))  # å»é‡å¹¶æ’åº
#     print(f"æ€»å…±æ‰«æåˆ° {len(all_images)} ä¸ªPNGå›¾åƒæ–‡ä»¶")
    
#     if len(all_images) == 0:
#         raise ValueError(f"åœ¨ {train_img_dir} ä¸­æœªæ‰¾åˆ°PNGå›¾åƒæ–‡ä»¶")
    
#     # ä½¿ç”¨å›ºå®šåˆ’åˆ†
#     train_images, val_images = get_fixed_split(all_images, split_ratio)
#     print(f"ğŸ“Š ä½¿ç”¨å›ºå®šåˆ’åˆ†ç­–ç•¥:")
#     print(f"   è®­ç»ƒé›†: {len(train_images)} å¼ å›¾åƒ")
#     print(f"   éªŒè¯é›†: {len(val_images)} å¼ å›¾åƒ")
#     print(f"   éªŒè¯é›†æ¯”ä¾‹: {len(val_images)/len(all_images):.1%}")
    
#     # åˆ›å»ºè®­ç»ƒå’ŒéªŒè¯æ•°æ®é›†
#     train_dataset = IronSpectrumDataset(
#         img_dir=train_img_dir,
#         mask_dir=train_mask_dir,
#         img_size=img_size,
#         is_train=True,
#         image_list=train_images,
#         transform=train_transform,
#         augment=True,
#         # Mixupå‚æ•°ï¼ˆä»…è®­ç»ƒé›†ï¼‰
#         enable_mixup=enable_mixup,
#         mixup_alpha=mixup_alpha,
#         mixup_prob=mixup_prob,
#         mixup_mode=mixup_mode
#     )
    
#     val_dataset = IronSpectrumDataset(
#         img_dir=train_img_dir,
#         mask_dir=train_mask_dir,
#         img_size=img_size,
#         is_train=False,
#         image_list=val_images,
#         transform=val_transform,
#         augment=False,
#         # éªŒè¯é›†ä¸ä½¿ç”¨Mixup
#         enable_mixup=False
#     )
    
#     # åˆ›å»ºæ•°æ®åŠ è½½å™¨
#     train_loader = DataLoader(
#         train_dataset,
#         batch_size=batch_size,
#         shuffle=True,
#         num_workers=num_workers,
#         pin_memory=pin_memory,
#         drop_last=True
#     )
    
#     val_loader = DataLoader(
#         val_dataset,
#         batch_size=batch_size,
#         shuffle=False,
#         num_workers=num_workers,
#         pin_memory=pin_memory
#     )
    
#     return train_loader, val_loader


# # å…¶ä»–å‡½æ•°ä¿æŒä¸å˜
# def get_fixed_split(all_images: List[str], split_ratio: float = 0.8) -> Tuple[List[str], List[str]]:
#     """
#     åŸºäºå“ˆå¸Œå€¼çš„å›ºå®šæ•°æ®é›†åˆ’åˆ†
    
#     Args:
#         all_images: æ‰€æœ‰å›¾åƒæ–‡ä»¶ååˆ—è¡¨
#         split_ratio: è®­ç»ƒé›†æ¯”ä¾‹
        
#     Returns:
#         (train_images, val_images): è®­ç»ƒé›†å’ŒéªŒè¯é›†å›¾åƒåˆ—è¡¨
#     """
#     def get_hash_value(filename):
#         """è·å–æ–‡ä»¶åçš„å“ˆå¸Œå€¼"""
#         return int(hashlib.md5(filename.encode()).hexdigest(), 16)
    
#     # æŒ‰æ–‡ä»¶åæ’åºç¡®ä¿ä¸€è‡´æ€§
#     sorted_images = sorted(all_images)
    
#     # è®¡ç®—æ¯ä¸ªæ–‡ä»¶çš„å“ˆå¸Œå€¼å¹¶æ’åº
#     image_hash_pairs = [(img, get_hash_value(img)) for img in sorted_images]
#     image_hash_pairs.sort(key=lambda x: x[1])  # æŒ‰å“ˆå¸Œå€¼æ’åº
    
#     # è®¡ç®—è®­ç»ƒé›†å¤§å°
#     train_size = int(len(sorted_images) * split_ratio)
    
#     # åŸºäºå“ˆå¸Œå€¼æ’åºçš„ç»“æœè¿›è¡Œåˆ’åˆ†
#     train_images = [pair[0] for pair in image_hash_pairs[:train_size]]
#     val_images = [pair[0] for pair in image_hash_pairs[train_size:]]
    
#     # ç¡®ä¿éªŒè¯é›†è‡³å°‘æœ‰ä¸€å®šæ•°é‡
#     min_val_size = max(1, int(len(sorted_images) * 0.1))  # è‡³å°‘10%
#     if len(val_images) < min_val_size:
#         # é‡æ–°è°ƒæ•´
#         train_size = len(sorted_images) - min_val_size
#         train_images = [pair[0] for pair in image_hash_pairs[:train_size]]
#         val_images = [pair[0] for pair in image_hash_pairs[train_size:]]
    
#     return train_images, val_images


# def create_test_dataloader(
#     test_img_dir: str,
#     test_mask_dir: str,
#     batch_size: int = 1,
#     img_size: int = 512,
#     num_workers: int = 4,
#     transform: Optional[Callable] = None
# ) -> DataLoader:
#     """
#     åˆ›å»ºæµ‹è¯•æ•°æ®åŠ è½½å™¨ï¼ˆç‹¬ç«‹äºè®­ç»ƒæ•°æ®ï¼Œä¸ä½¿ç”¨Mixupï¼‰
    
#     Args:
#         test_img_dir: æµ‹è¯•å›¾åƒç›®å½•
#         test_mask_dir: æµ‹è¯•æ©ç ç›®å½•
#         batch_size: æ‰¹æ¬¡å¤§å°ï¼ˆæµ‹è¯•æ—¶é€šå¸¸ä¸º1ï¼‰
#         img_size: å›¾åƒå°ºå¯¸
#         num_workers: æ•°æ®åŠ è½½å·¥ä½œè¿›ç¨‹æ•°
#         transform: è‡ªå®šä¹‰å˜æ¢
        
#     Returns:
#         test_loader: æµ‹è¯•æ•°æ®åŠ è½½å™¨
#     """
#     print("ğŸ”§ åˆ›å»ºæµ‹è¯•æ•°æ®åŠ è½½å™¨ï¼ˆç‹¬ç«‹æµ‹è¯•é›†ï¼‰")
    
#     test_dataset = IronSpectrumDataset(
#         img_dir=test_img_dir,
#         mask_dir=test_mask_dir,
#         img_size=img_size,
#         is_train=False,
#         transform=transform,
#         augment=False,
#         enable_mixup=False  # æµ‹è¯•é›†ä¸ä½¿ç”¨Mixup
#     )
    
#     test_loader = DataLoader(
#         test_dataset,
#         batch_size=batch_size,
#         shuffle=False,
#         num_workers=num_workers,
#         pin_memory=True
#     )
    
#     print(f"âœ… æµ‹è¯•æ•°æ®åŠ è½½å™¨åˆ›å»ºå®Œæˆ:")
#     print(f"   æ‰¹æ¬¡æ•°é‡: {len(test_loader)}")
#     print(f"   æ ·æœ¬æ€»æ•°: {len(test_dataset)}")
#     print(f"   æ‰¹æ¬¡å¤§å°: {batch_size}")
    
#     return test_loader


# def save_split_info(train_images: List[str], val_images: List[str], save_path: str):
#     """ä¿å­˜æ•°æ®é›†åˆ’åˆ†ä¿¡æ¯åˆ°æ–‡ä»¶"""
#     os.makedirs(os.path.dirname(save_path), exist_ok=True)
    
#     with open(save_path, 'w', encoding='utf-8') as f:
#         f.write("=== æ•°æ®é›†åˆ’åˆ†ä¿¡æ¯ ===\n")
#         f.write(f"è®­ç»ƒé›†æ•°é‡: {len(train_images)}\n")
#         f.write(f"éªŒè¯é›†æ•°é‡: {len(val_images)}\n")
#         f.write(f"æ€»æ•°é‡: {len(train_images) + len(val_images)}\n")
#         f.write(f"éªŒè¯é›†æ¯”ä¾‹: {len(val_images)/(len(train_images) + len(val_images)):.1%}\n\n")
        
#         f.write("è®­ç»ƒé›†å›¾åƒ:\n")
#         for img in sorted(train_images):
#             f.write(f"  {img}\n")
        
#         f.write("\néªŒè¯é›†å›¾åƒ:\n")
#         for img in sorted(val_images):
#             f.write(f"  {img}\n")
    
#     print(f"ğŸ“ æ•°æ®é›†åˆ’åˆ†ä¿¡æ¯å·²ä¿å­˜è‡³: {save_path}")


# def verify_data_structure(train_img_dir: str, train_mask_dir: str, test_img_dir: str, test_mask_dir: str):
#     """éªŒè¯æ•°æ®ç»“æ„æ˜¯å¦æ­£ç¡®"""
#     print("ğŸ” éªŒè¯æ•°æ®ç»“æ„...")
    
#     def check_directory(path, description):
#         if os.path.exists(path):
#             png_files = [f for f in os.listdir(path) if f.endswith('.png')]
#             print(f"   {description}: {len(png_files)} ä¸ªPNGæ–‡ä»¶")
#             return len(png_files)
#         else:
#             print(f"   {description}: ç›®å½•ä¸å­˜åœ¨")
#             return 0
    
#     print(f"ğŸ“ æ•°æ®ç»“æ„éªŒè¯:")
#     train_img_count = check_directory(train_img_dir, "è®­ç»ƒå›¾åƒ")
#     train_mask_count = check_directory(train_mask_dir, "è®­ç»ƒæ ‡ç­¾")
#     test_img_count = check_directory(test_img_dir, "æµ‹è¯•å›¾åƒ")
#     test_mask_count = check_directory(test_mask_dir, "æµ‹è¯•æ ‡ç­¾")
    
#     if train_img_count > 0 and test_img_count > 0:
#         print("âœ… æ•°æ®ç»“æ„éªŒè¯é€šè¿‡")
#         return True
#     else:
#         print("âŒ æ•°æ®ç»“æ„éªŒè¯å¤±è´¥")
#         return False


# def test_dataset(train_img_dir: str = None, train_mask_dir: str = None, 
#                 test_img_dir: str = None, test_mask_dir: str = None):
#     """
#     æµ‹è¯•æ•°æ®é›†åŠŸèƒ½ï¼ˆåŒ…æ‹¬Mixupï¼‰
    
#     Args:
#         train_img_dir: è®­ç»ƒå›¾åƒç›®å½•ï¼ˆå¯é€‰ï¼Œå¦‚æœä¸æä¾›åˆ™ä½¿ç”¨é»˜è®¤è·¯å¾„ï¼‰
#         train_mask_dir: è®­ç»ƒæ ‡ç­¾ç›®å½•ï¼ˆå¯é€‰ï¼‰
#         test_img_dir: æµ‹è¯•å›¾åƒç›®å½•ï¼ˆå¯é€‰ï¼‰
#         test_mask_dir: æµ‹è¯•æ ‡ç­¾ç›®å½•ï¼ˆå¯é€‰ï¼‰
#     """
#     print("ğŸš€ é“è°±æ•°æ®é›†åŠŸèƒ½æµ‹è¯• (åŒ…å«Mixup)")
#     print("=" * 60)
    
#     # å¦‚æœæ²¡æœ‰æä¾›è·¯å¾„ï¼Œä½¿ç”¨é»˜è®¤è·¯å¾„
#     if train_img_dir is None:
#         current_dir = os.getcwd()
#         train_img_dir = os.path.join(current_dir, 'data', 'train', 'images')
#         train_mask_dir = os.path.join(current_dir, 'data', 'train', 'labels')
#         test_img_dir = os.path.join(current_dir, 'data', 'test', 'images')
#         test_mask_dir = os.path.join(current_dir, 'data', 'test', 'labels')
    
#     # éªŒè¯æ•°æ®ç»“æ„
#     if not verify_data_structure(train_img_dir, train_mask_dir, test_img_dir, test_mask_dir):
#         return
    
#     try:
#         # æµ‹è¯•æ ‡å‡†è®­ç»ƒ/éªŒè¯æ•°æ®åŠ è½½å™¨
#         print(f"\nğŸ”„ æµ‹è¯•æ ‡å‡†è®­ç»ƒ/éªŒè¯æ•°æ®åŠ è½½å™¨...")
#         train_loader, val_loader = create_train_val_dataloaders(
#             train_img_dir=train_img_dir,
#             train_mask_dir=train_mask_dir,
#             batch_size=4,
#             img_size=512,
#             num_workers=0,
#             split_ratio=0.8,
#             enable_mixup=False
#         )
        
#         print(f"æ ‡å‡†æ•°æ®åŠ è½½å™¨åˆ›å»ºæˆåŠŸ!")
#         print(f"   è®­ç»ƒé›†æ‰¹æ¬¡æ•°é‡: {len(train_loader)}")
#         print(f"   éªŒè¯é›†æ‰¹æ¬¡æ•°é‡: {len(val_loader)}")
        
#         # æµ‹è¯•Mixupæ•°æ®åŠ è½½å™¨
#         print(f"\nğŸ”„ æµ‹è¯•Mixupè®­ç»ƒæ•°æ®åŠ è½½å™¨...")
#         mixup_modes = ['mixup', 'cutmix', 'segmix']
        
#         for mode in mixup_modes:
#             print(f"\nğŸ“Š æµ‹è¯• {mode.upper()} æ¨¡å¼:")
            
#             mixup_train_loader, _ = create_train_val_dataloaders(
#                 train_img_dir=train_img_dir,
#                 train_mask_dir=train_mask_dir,
#                 batch_size=2,
#                 img_size=256,  # ä½¿ç”¨è¾ƒå°å°ºå¯¸åŠ å¿«æµ‹è¯•
#                 num_workers=0,
#                 split_ratio=0.8,
#                 enable_mixup=True,
#                 mixup_alpha=1.0,
#                 mixup_prob=0.8,
#                 mixup_mode=mode
#             )
            
#             # æµ‹è¯•åŠ è½½å‡ ä¸ªæ‰¹æ¬¡
#             mixup_count = 0
#             normal_count = 0
            
#             for i, batch in enumerate(mixup_train_loader):
#                 if i >= 3:  # åªæµ‹è¯•å‰3ä¸ªæ‰¹æ¬¡
#                     break
                    
#                 print(f"   æ‰¹æ¬¡ {i+1}:")
#                 print(f"     å›¾åƒå½¢çŠ¶: {batch['image'].shape}")
#                 print(f"     æ©ç å½¢çŠ¶: {batch['mask'].shape}")
                
#                 if isinstance(batch['is_mixup'], torch.Tensor):
#                     is_mixup_list = batch['is_mixup'].tolist()
#                 else:
#                     is_mixup_list = [batch['is_mixup']] if not isinstance(batch['is_mixup'], list) else batch['is_mixup']
                
#                 for j, is_mixup in enumerate(is_mixup_list):
#                     if is_mixup:
#                         mixup_count += 1
#                         # å®‰å…¨åœ°è·å–mixup_lam
#                         lam = None
#                         if 'mixup_lam' in batch:
#                             if isinstance(batch['mixup_lam'], (list, torch.Tensor)) and len(batch['mixup_lam']) > j:
#                                 lam = batch['mixup_lam'][j] if isinstance(batch['mixup_lam'], (list, torch.Tensor)) else batch['mixup_lam']
#                             elif not isinstance(batch['mixup_lam'], (list, torch.Tensor)):
#                                 lam = batch['mixup_lam']
                        
#                         if lam is not None:
#                             print(f"     æ ·æœ¬ {j}: Mixupæ ·æœ¬ (Î»={lam:.3f})")
#                         else:
#                             print(f"     æ ·æœ¬ {j}: Mixupæ ·æœ¬")
#                     else:
#                         normal_count += 1
#                         print(f"     æ ·æœ¬ {j}: æ ‡å‡†æ ·æœ¬")
            
#             print(f"   {mode} æµ‹è¯•ç»“æœ: {mixup_count} ä¸ªMixupæ ·æœ¬, {normal_count} ä¸ªæ ‡å‡†æ ·æœ¬")
        
#         print(f"\nâœ… Mixupæ•°æ®é›†åŠŸèƒ½æµ‹è¯•å®Œæˆ!")
        
#     except Exception as e:
#         print(f"âŒ æ•°æ®é›†æµ‹è¯•å¤±è´¥: {e}")
#         import traceback
#         traceback.print_exc()


# if __name__ == "__main__":
#     # æµ‹è¯•æ•°æ®é›†åŠŸèƒ½ï¼ŒåŒ…æ‹¬Mixup
#     test_dataset()