import os
import numpy as np
import torch
import torch.nn as nn
import torch.nn.functional as F
import cv2
import matplotlib.pyplot as plt
from tqdm import tqdm
from scipy.ndimage import distance_transform_edt
from models.HMA_UNet import create_hma_unet, load_hma_unet
import argparse
from datetime import datetime


class HMAUNetTester:
    def __init__(self, config):
        self.config = config
        self.device = torch.device(config.device)

        # åˆ›å»ºä¿å­˜ç›®å½•
        os.makedirs(config.save_dir, exist_ok=True)

        # åˆå§‹åŒ–HMA-UNetæ¨¡å‹ - ç®€åŒ–ä¸ºåªæ”¯æŒbaseé…ç½®
        print(f"ğŸ”§ åŠ è½½HMA-UNetæ¨¡å‹: base (å”¯ä¸€å¯ç”¨é…ç½®)")
        
        if hasattr(config, 'model_path') and config.model_path and os.path.exists(config.model_path):
            # ä»æ£€æŸ¥ç‚¹åŠ è½½æ¨¡å‹
            print(f"ğŸ“‚ ä»æ£€æŸ¥ç‚¹åŠ è½½: {config.model_path}")
            
            self.model = load_hma_unet(
                filepath=config.model_path,
                config="base",  # å¼ºåˆ¶ä½¿ç”¨baseé…ç½®
                in_channels=3,
                num_classes=1
            ).to(self.device)
            print(f"âœ… æ¨¡å‹å·²ä» {config.model_path} åŠ è½½")
        else:
            # åˆ›å»ºæ–°æ¨¡å‹ï¼ˆç”¨äºæµ‹è¯•æ¶æ„ï¼‰
            print("âš ï¸ æœªæŒ‡å®šæœ‰æ•ˆæ¨¡å‹è·¯å¾„ï¼Œåˆ›å»ºæœªè®­ç»ƒçš„baseæ¨¡å‹")
            self.model = create_hma_unet(
                config="base",  # å¼ºåˆ¶ä½¿ç”¨base
                in_channels=3,
                num_classes=1
            ).to(self.device)

        self.model.eval()
        print(f"âœ… æ¨¡å‹åŠ è½½å®Œæˆ (é…ç½®: base)")
        
        # æ‰“å°æ¨¡å‹ä¿¡æ¯
        try:
            model_info = self.model.get_model_info()
            print(f"ğŸ“Š æ¨¡å‹å‚æ•°é‡: {model_info['total_params']:,}")
            print(f"ğŸ“Š åŸºç¡€é€šé“æ•°: {model_info['base_channels']}")
        except Exception as e:
            print(f"âš ï¸ æ— æ³•è·å–æ¨¡å‹ä¿¡æ¯: {e}")

    def preprocess_image(self, image):
        """é¢„å¤„ç†å›¾åƒ"""
        # è½¬æ¢ä¸ºtensor
        image_tensor = torch.from_numpy(image.transpose(2, 0, 1)).float()
        image_tensor = image_tensor / 255.0

        # æ·»åŠ å½’ä¸€åŒ–
        mean = torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1)
        std = torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1)
        image_tensor = (image_tensor - mean) / std

        return image_tensor.unsqueeze(0)

    def calculate_hd95(self, pred, target):
        """è®¡ç®—95%è±ªæ–¯å¤šå¤«è·ç¦»"""
        if pred.sum() == 0 and target.sum() == 0:
            return 0.0
        if pred.sum() == 0 or target.sum() == 0:
            return 373.0  # å›¾åƒå¯¹è§’çº¿é•¿åº¦ä½œä¸ºæœ€å¤§è·ç¦»

        # è®¡ç®—è¾¹ç•Œç‚¹
        pred_boundary = pred ^ cv2.erode(pred.astype(np.uint8), np.ones((3, 3)))
        target_boundary = target ^ cv2.erode(target.astype(np.uint8), np.ones((3, 3)))

        pred_points = np.argwhere(pred_boundary)
        target_points = np.argwhere(target_boundary)

        if len(pred_points) == 0 or len(target_points) == 0:
            return 373.0

        # è®¡ç®—è·ç¦»
        distances = []
        for point in pred_points:
            min_dist = np.min(np.sqrt(np.sum((target_points - point) ** 2, axis=1)))
            distances.append(min_dist)

        for point in target_points:
            min_dist = np.min(np.sqrt(np.sum((pred_points - point) ** 2, axis=1)))
            distances.append(min_dist)

        return np.percentile(distances, 95)

    def calculate_metrics(self, pred, target):
        """è®¡ç®—å‡†ç¡®ç‡ã€HD95ã€Diceå’ŒIoUå››ä¸ªæŒ‡æ ‡"""
        pred_bin = pred > 0.5
        target_bin = target > 0.5

        # è®¡ç®—åŸºæœ¬æŒ‡æ ‡ï¼šTP, TN, FP, FN
        TP = np.logical_and(pred_bin, target_bin).sum()
        TN = np.logical_and(~pred_bin, ~target_bin).sum()
        FP = np.logical_and(pred_bin, ~target_bin).sum()
        FN = np.logical_and(~pred_bin, target_bin).sum()
        
        # è®¡ç®—æ€»åƒç´ æ•°
        N = pred.size
        
        # 1. Diceç³»æ•° (DSC)
        dice = 2 * TP / (2 * TP + FP + FN + 1e-6)
        
        # 2. IoU (äº¤å¹¶æ¯”)
        iou = TP / (TP + FP + FN + 1e-6)
        
        # 3. å‡†ç¡®ç‡ (ACC)
        acc = (TP + TN) / (N + 1e-6)
        
        # 4. 95%è±ªæ–¯å¤šå¤«è·ç¦» (HD95)
        hd95 = self.calculate_hd95(pred_bin, target_bin)
        
        return {
            'dice': dice,
            'iou': iou,
            'accuracy': acc,
            'hd95': hd95
        }

    def draw_contours(self, image, mask):
        """åœ¨åŸå›¾ä¸Šç»˜åˆ¶åˆ†å‰²è¾¹ç¼˜"""
        binary_mask = (mask > 0.5).astype(np.uint8) * 255
        contours, _ = cv2.findContours(
            binary_mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE
        )
        result = image.copy()
        cv2.drawContours(result, contours, -1, (0, 255, 0), 2)
        return result, binary_mask

    def test(self):
        print(f"ğŸš€ å¼€å§‹æµ‹è¯•HMA-UNetæ¨¡å‹ (é…ç½®: base)...")
        
        # ç›´æ¥ä»testç›®å½•è·å–å›¾åƒåˆ—è¡¨
        test_images = sorted([
            f for f in os.listdir(self.config.test_img_dir) 
            if f.lower().endswith(('.png', '.jpg', '.jpeg'))
        ])
        
        print(f"ğŸ“‚ ä» {self.config.test_img_dir} æ‰¾åˆ° {len(test_images)} å¼ æµ‹è¯•å›¾åƒ")
        
        if len(test_images) == 0:
            print(f"âŒ åœ¨ {self.config.test_img_dir} ä¸­æœªæ‰¾åˆ°å›¾åƒæ–‡ä»¶")
            return

        # åˆå§‹åŒ–å››ä¸ªæŒ‡æ ‡çš„ç´¯åŠ å™¨
        metrics_sum = {
            'dice': 0, 
            'iou': 0, 
            'accuracy': 0, 
            'hd95': 0
        }
        
        # è®°å½•æ¯å¼ å›¾ç‰‡çš„æŒ‡æ ‡
        image_metrics = {}

        # åˆ›å»ºå­ç›®å½•ç”¨äºä¿å­˜ä¸åŒç±»å‹çš„å›¾åƒ
        original_dir = os.path.join(self.config.save_dir, "original")
        binary_dir = os.path.join(self.config.save_dir, "binary")
        contour_dir = os.path.join(self.config.save_dir, "contour")
        groundtruth_dir = os.path.join(self.config.save_dir, "groundtruth")
        
        # åˆ›å»ºå­ç›®å½•
        for dir_path in [original_dir, binary_dir, contour_dir, groundtruth_dir]:
            os.makedirs(dir_path, exist_ok=True)

        with torch.no_grad():
            for image_name in tqdm(test_images, desc="å¤„ç†æµ‹è¯•å›¾åƒ"):
                # è¯»å–å›¾åƒå’Œæ ‡ç­¾
                image_path = os.path.join(self.config.test_img_dir, image_name)
                mask_path = os.path.join(self.config.test_mask_dir, image_name)
                
                # è¯»å–å›¾åƒ
                image = cv2.imread(image_path)
                if image is None:
                    print(f"âš ï¸ æ— æ³•è¯»å–å›¾åƒ: {image_path}")
                    continue
                    
                image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
                
                # è¯»å–æ ‡ç­¾
                mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)
                if mask is None:
                    print(f"âš ï¸ æ— æ³•è¯»å–æ ‡ç­¾: {mask_path}")
                    # åˆ›å»ºç©ºæ ‡ç­¾
                    mask = np.zeros((image.shape[0], image.shape[1]), dtype=np.uint8)
                
                # é¢„å¤„ç†å›¾åƒ
                image_tensor = self.preprocess_image(image)
                image_tensor = image_tensor.to(self.device)

                # è°ƒæ•´å¤§å°ä¸ºæ¨¡å‹è¾“å…¥å°ºå¯¸
                input_tensor = F.interpolate(
                    image_tensor,
                    size=(self.config.img_size, self.config.img_size),
                    mode="bilinear",
                    align_corners=True,
                )

                # æ¨¡å‹é¢„æµ‹
                output = self.model(input_tensor)
                pred = torch.sigmoid(output)

                # è¿˜åŸåˆ°åŸå§‹å°ºå¯¸
                pred = F.interpolate(
                    pred,
                    size=(image.shape[0], image.shape[1]),
                    mode="bilinear",
                    align_corners=True,
                )

                # è½¬æ¢é¢„æµ‹ç»“æœ
                pred_np = pred[0, 0].cpu().numpy()
                mask_np = mask / 255.0

                # è®¡ç®—è¯„ä»·æŒ‡æ ‡
                metrics = self.calculate_metrics(pred_np, mask_np)
                image_metrics[image_name] = metrics
                
                # ç´¯åŠ æŒ‡æ ‡
                for key in metrics_sum:
                    metrics_sum[key] += metrics[key]

                # ç»˜åˆ¶åˆ†å‰²è¾¹ç¼˜
                contour_result, binary_pred = self.draw_contours(image, pred_np)
                
                # ä¿å­˜å›¾åƒ
                # 1. åŸå›¾
                cv2.imwrite(
                    os.path.join(original_dir, image_name),
                    cv2.cvtColor(image, cv2.COLOR_RGB2BGR)
                )
                
                # 2. çœŸå®æ ‡ç­¾
                cv2.imwrite(
                    os.path.join(groundtruth_dir, image_name),
                    mask
                )
                
                # 3. é¢„æµ‹ç»“æœï¼ˆäºŒå€¼åŒ–ï¼‰
                cv2.imwrite(os.path.join(binary_dir, image_name), binary_pred)
                
                # 4. è½®å»“å åŠ å›¾
                cv2.imwrite(
                    os.path.join(contour_dir, image_name),
                    cv2.cvtColor(contour_result, cv2.COLOR_RGB2BGR)
                )

        # è®¡ç®—å¹³å‡æŒ‡æ ‡
        num_images = len(image_metrics)
        if num_images == 0:
            print("âŒ æ²¡æœ‰æˆåŠŸå¤„ç†ä»»ä½•å›¾åƒ")
            return
            
        avg_metrics = {k: v / num_images for k, v in metrics_sum.items()}

        # æ‰¾å‡ºHD95æœ€é«˜çš„5å¼ å›¾ç‰‡
        hd95_sorted = sorted(image_metrics.items(), key=lambda x: x[1]['hd95'], reverse=True)[:5]

        # æ‰“å°ç»“æœ
        print("\n===== HMA-UNetæ¨¡å‹åˆ†å‰²æ€§èƒ½è¯„ä¼°ç»“æœ =====")
        print(f"æ¨¡å‹é…ç½®: base (å”¯ä¸€å¯ç”¨é…ç½®)")
        print(f"æµ‹è¯•å›¾åƒæ•°é‡: {num_images}")
        print(f"Diceç³»æ•° (DSC): {avg_metrics['dice']:.4f}")
        print(f"äº¤å¹¶æ¯” (IoU): {avg_metrics['iou']:.4f}")
        print(f"å‡†ç¡®ç‡ (ACC): {avg_metrics['accuracy']:.4f}")
        print(f"95%è±ªæ–¯å¤šå¤«è·ç¦» (HD95): {avg_metrics['hd95']:.4f} åƒç´ ")
        print("==========================")

        # æ‰“å°HD95æœ€é«˜çš„å›¾ç‰‡
        print("\n===== HD95æœ€é«˜çš„5å¼ å›¾ç‰‡ =====")
        for i, (img_name, metrics) in enumerate(hd95_sorted):
            print(f"{i+1}. {img_name}: HD95={metrics['hd95']:.4f}, Dice={metrics['dice']:.4f}")
        print("==========================")

        # ä¿å­˜è¯„ä»·æŒ‡æ ‡
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        metrics_file = os.path.join(self.config.save_dir, f"metrics_{timestamp}.txt")
        
        with open(metrics_file, "w", encoding='utf-8') as f:
            f.write("===== HMA-UNetæ¨¡å‹åˆ†å‰²æ€§èƒ½è¯„ä¼°ç»“æœ =====\n")
            f.write(f"æ¨¡å‹é…ç½®: base (å”¯ä¸€å¯ç”¨é…ç½®)\n")
            if hasattr(self.config, 'model_path') and self.config.model_path:
                f.write(f"æ¨¡å‹è·¯å¾„: {self.config.model_path}\n")
            f.write(f"æµ‹è¯•å›¾åƒæ•°é‡: {num_images}\n")
            f.write(f"Diceç³»æ•° (DSC): {avg_metrics['dice']:.4f}\n")
            f.write(f"äº¤å¹¶æ¯” (IoU): {avg_metrics['iou']:.4f}\n")
            f.write(f"å‡†ç¡®ç‡ (ACC): {avg_metrics['accuracy']:.4f}\n")
            f.write(f"95%è±ªæ–¯å¤šå¤«è·ç¦» (HD95): {avg_metrics['hd95']:.4f} åƒç´ \n")
            f.write("==========================\n\n")
            
            # ä¿å­˜HD95æœ€é«˜çš„å›¾ç‰‡ä¿¡æ¯
            f.write("===== HD95æœ€é«˜çš„5å¼ å›¾ç‰‡ =====\n")
            for i, (img_name, metrics) in enumerate(hd95_sorted):
                f.write(f"{i+1}. {img_name}: HD95={metrics['hd95']:.4f}, Dice={metrics['dice']:.4f}\n")
            f.write("==========================\n\n")
            
            # ä¿å­˜è¯¦ç»†æŒ‡æ ‡ï¼ˆæ¯å¼ å›¾ç‰‡ï¼‰
            f.write("===== è¯¦ç»†æŒ‡æ ‡ï¼ˆæ¯å¼ å›¾ç‰‡ï¼‰ =====\n")
            for img_name, metrics in image_metrics.items():
                f.write(f"{img_name}: Dice={metrics['dice']:.4f}, IoU={metrics['iou']:.4f}, "
                       f"ACC={metrics['accuracy']:.4f}, HD95={metrics['hd95']:.4f}\n")
        
        print(f"\nğŸ“ ç»“æœå·²ä¿å­˜è‡³ {self.config.save_dir}")
        print(f"ğŸ“„ æŒ‡æ ‡æ–‡ä»¶: {metrics_file}")
        return avg_metrics


def get_available_configs():
    """è·å–å¯ç”¨çš„æ¨¡å‹é…ç½® - ç®€åŒ–ä¸ºåªæ”¯æŒbase"""
    return ['base']


def parse_args():
    """è§£æå‘½ä»¤è¡Œå‚æ•° - ç®€åŒ–ç‰ˆæœ¬"""
    parser = argparse.ArgumentParser(description='HMA-UNetæ¨¡å‹æµ‹è¯• (ä»…æ”¯æŒbaseé…ç½®)')
    
    # æ¨¡å‹ç›¸å…³å‚æ•° - ç®€åŒ–
    parser.add_argument('--model_path', type=str, default=None,
                       help='è®­ç»ƒå¥½çš„æ¨¡å‹è·¯å¾„ï¼ˆ.pthæ–‡ä»¶ï¼‰')
    
    # æ•°æ®ç›¸å…³å‚æ•°
    parser.add_argument('--test_img_dir', type=str, default='./data/test/images',
                       help='æµ‹è¯•å›¾åƒç›®å½•')
    parser.add_argument('--test_mask_dir', type=str, default='./data/test/labels',
                       help='æµ‹è¯•æ ‡ç­¾ç›®å½•')
    parser.add_argument('--img_size', type=int, default=512,
                       help='è¾“å…¥å›¾åƒå°ºå¯¸')
    
    # è¾“å‡ºç›¸å…³å‚æ•°
    parser.add_argument('--save_dir', type=str, default='./results/test/',
                       help='ç»“æœä¿å­˜ç›®å½•')
    
    # ç³»ç»Ÿå‚æ•°
    parser.add_argument('--device', type=str, default='auto',
                       help='è®¡ç®—è®¾å¤‡ (auto/cuda/cpu)')
    
    return parser.parse_args()


class Config:
    """é…ç½®ç±» - ç®€åŒ–ç‰ˆæœ¬"""
    def __init__(self, args):
        # ä»å‘½ä»¤è¡Œå‚æ•°åˆå§‹åŒ–
        for key, value in vars(args).items():
            setattr(self, key, value)
        
        # å›ºå®šä½¿ç”¨baseé…ç½®
        self.model_config = 'base'
        
        # è‡ªåŠ¨è®¾å¤‡é€‰æ‹©
        if self.device == 'auto':
            self.device = "cuda" if torch.cuda.is_available() else "cpu"
        
        # ç¡®ä¿ç›®å½•å­˜åœ¨
        os.makedirs(self.save_dir, exist_ok=True)


def main():
    """ä¸»å‡½æ•°"""
    # è§£æå‘½ä»¤è¡Œå‚æ•°
    args = parse_args()
    config = Config(args)
    
    # æ‰“å°é…ç½®ä¿¡æ¯
    print("=" * 60)
    print("HMA-UNet æ¨¡å‹æµ‹è¯•é…ç½® (ä»…æ”¯æŒbase)")
    print("=" * 60)
    print(f"æ¨¡å‹é…ç½®: base (å”¯ä¸€å¯ç”¨)")
    if config.model_path:
        print(f"æ¨¡å‹è·¯å¾„: {config.model_path}")
        print(f"æ¨¡å‹æ–‡ä»¶å­˜åœ¨: {os.path.exists(config.model_path) if config.model_path else False}")
    else:
        print("æ¨¡å‹è·¯å¾„: æœªæŒ‡å®š (å°†åˆ›å»ºæœªè®­ç»ƒæ¨¡å‹)")
    print(f"æµ‹è¯•å›¾åƒç›®å½•: {config.test_img_dir}")
    print(f"æµ‹è¯•æ ‡ç­¾ç›®å½•: {config.test_mask_dir}")
    print(f"å›¾åƒå°ºå¯¸: {config.img_size}")
    print(f"è®¾å¤‡: {config.device}")
    print(f"ç»“æœä¿å­˜ç›®å½•: {config.save_dir}")
    print("=" * 60)
    
    # éªŒè¯æ•°æ®ç›®å½•
    if not os.path.exists(config.test_img_dir):
        print(f"âŒ æµ‹è¯•å›¾åƒç›®å½•ä¸å­˜åœ¨: {config.test_img_dir}")
        print("è¯·æ£€æŸ¥è·¯å¾„æˆ–åˆ›å»ºæµ‹è¯•æ•°æ®")
        return
    
    if not os.path.exists(config.test_mask_dir):
        print(f"âŒ æµ‹è¯•æ ‡ç­¾ç›®å½•ä¸å­˜åœ¨: {config.test_mask_dir}")
        print("è¯·æ£€æŸ¥è·¯å¾„æˆ–åˆ›å»ºæµ‹è¯•æ ‡ç­¾")
        return
    
    # æ£€æŸ¥CUDAå¯ç”¨æ€§
    if config.device == 'cuda' and not torch.cuda.is_available():
        print("âš ï¸ CUDAä¸å¯ç”¨ï¼Œåˆ‡æ¢åˆ°CPU")
        config.device = 'cpu'
    
    # å¼€å§‹æµ‹è¯•
    try:
        tester = HMAUNetTester(config)
        print("\nğŸ¯ å¼€å§‹æ¨¡å‹æµ‹è¯•...")
        metrics = tester.test()
        
        if metrics:
            print("\nğŸ‰ æµ‹è¯•å®Œæˆï¼")
            print(f"ğŸ“Š æœ€ç»ˆç»“æœ: Dice={metrics['dice']:.4f}, IoU={metrics['iou']:.4f}, "
                  f"ACC={metrics['accuracy']:.4f}, HD95={metrics['hd95']:.4f}")
        else:
            print("âŒ æµ‹è¯•å¤±è´¥")
            
    except Exception as e:
        print(f"âŒ æµ‹è¯•è¿‡ç¨‹å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    # å¯ä»¥ç›´æ¥è¿è¡Œçš„ç®€åŒ–ç‰ˆæœ¬
    class SimpleConfig:
        img_size = 512
        model_path = "./checkpoints/HMA_UNet/HMA_UNet_base_20250627_101313/HMA_UNet_base_best_model.pth"  # æ ¹æ®æ‚¨çš„å·¥ä½œç©ºé—´è°ƒæ•´
        test_img_dir = "./data/test/images/"  # ä½¿ç”¨æ‚¨å·¥ä½œç©ºé—´ä¸­çš„testç›®å½•
        test_mask_dir = "./data/test/labels/"  # ä½¿ç”¨æ‚¨å·¥ä½œç©ºé—´ä¸­çš„testç›®å½•
        save_dir = "./results/HMA_UNet/"
        device = "cuda" if torch.cuda.is_available() else "cpu"

    # æ£€æŸ¥æ˜¯å¦æœ‰å‘½ä»¤è¡Œå‚æ•°
    import sys
    if len(sys.argv) > 1:
        # æœ‰å‘½ä»¤è¡Œå‚æ•°ï¼Œä½¿ç”¨argparse
        main()
    else:
        # æ²¡æœ‰å‘½ä»¤è¡Œå‚æ•°ï¼Œä½¿ç”¨ç®€åŒ–é…ç½®ç›´æ¥è¿è¡Œ
        print("ğŸš€ ä½¿ç”¨é»˜è®¤é…ç½®è¿è¡ŒHMA-UNetæµ‹è¯•")
        tester = HMAUNetTester(SimpleConfig())
        metrics = tester.test()
        
        if metrics:
            print("\nğŸ‰ æµ‹è¯•å®Œæˆï¼")
            print(f"ğŸ“Š æœ€ç»ˆç»“æœ: Dice={metrics['dice']:.4f}, IoU={metrics['iou']:.4f}, "
                  f"ACC={metrics['accuracy']:.4f}, HD95={metrics['hd95']:.4f}")
        else:
            print("âŒ æµ‹è¯•å¤±è´¥")